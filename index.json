{"project": "scikit-learn", "project_url": "scikit-learn.org/", "show_commit_url": "https://github.com/scikit-learn/scikit-learn/commit/", "hash_length": 8, "revision_to_hash": {"382": "e6989efd71a2adddd03979d1fe7a2e82e37ea51f", "395": "8ff9fc895bd6032636e3716f02773fdcd9cdd3d3", "587": "0e1faafec9871df73e875a0aadfcb67ec578c0e5", "590": "a40d325cec40da6cbcff8193a4ab4890823dfc76", "646": "ddc6d8f80dcf0a6cdd606efdefb89211a4dc7e9d", "745": "8a4bc2f03733e530591d6641f266a60670a373f1", "755": "8216797c4b1abca9dafd8de9d65472d32450b389", "811": "c7208c1a43335179ccddafc7748c1d7224e904fc", "813": "47890ac823314f1a9e2920dff7575850af56c273", "826": "b573fc0dcbfc2528807b5f0f8c0bc719c25d36f4", "998": "65d06f830ec6604b44d1a0510255868a8f762e3a", "1016": "9072aa593d76262fe445cf492ffac77e853501ea", "1131": "959e267898090e3c68ee118d5048afad124ff61d", "1207": "c83447b72c4f48ceb8249ea394ebf042618b8a2a", "1288": "f13dba15e3d56455c58867685ec554755a346c32", "1915": "d6b4444bbcc54a241cc955a5ceea80be15e7db2b", "1917": "60589710bd64e1fb2ede4d34d7fbb57e83892c86", "1919": "eba9984f735478d47c956ede42bdefd28aa6f9f6", "1969": "0f148e0011fb873bcd70cb3cc01690e7d621f670", "1977": "dc72677a9c13a656cda8be4b23cd897b56109b4b", "2701": "2c3d9e2fce5d2bae27e10657aa3c7ff45c39b190", "2711": "87741a7c65768464eb15f0976ed4bf6312795e7f", "2743": "03a85c19ac2854f2a33f613f87e81fd5f4560f55", "3102": "c07f9574c902b68744434d7b43f7394e0801d64e", "3151": "8a195624128da773c7d584d9352f65d8241cc92d", "3212": "897201083fd584a310cb8a2870704470dc28474a", "3289": "bdf3332f9694f8ecbdcf7ab0391989e24ac13f88", "3741": "5a1e1f48433ba867fb035b9dc31882f8d90f7744", "3905": "af6ab92b3bc0286e401218631859ee50f8be23f7", "4037": "f7c9f24511d9b32add23e75bbf0a2a6c223d932f", "4054": "8b2aaf069306d6b61b49a29d32123e69991c153b", "4684": "cf5c72eb9dc7696b5fac61466605b2860942946e", "4696": "3b48abd5fb0fa4f87c09f6b21d0d1f0e8b7873e4", "6177": "3e3872cde115550b75bb25c47c109b8bfd070eab", "6225": "3f1ea662ee1b1b08cee63cc31e4e3e36ec532208", "6511": "bfd36aa504078ce58f727f7f37e17349ab290e7d", "7872": "4533aa33daa35dd68c6d433b1d3560ff2b65b252", "7904": "34334f5ce6b1f166efda8652310133f9fc36ed04", "7919": "79749fd2939781e201191ef081143d8a575984e7", "9331": "34c2904a95a707c6e6148480a7e2c86a0f7ad86b", "9349": "73fdf6a9c982758be6da71a932ec4a3613eccbbf", "9357": "4ae44b0fe10b3ddf8390cfa8deae4dec45c40666", "9369": "7eb39fa0dc43ce485d3af2857c587811332eb148", "9799": "114822b1e18c9d7f887c58b8a3b2c279bdce6d35", "10413": "4bc8822c846de0d3b70d006ea32235d4375a575b", "10436": "0fede44fb39d691e873d58a4210452aa93c462a5", "10457": "b9ed384195df7b8d7824eac42f7b1bee58ef321c", "10778": "0dd2e39c1f7aec6830e4348fa63a04939252a0a1", "12368": "3e89aa5f42519d7f0230b99948553a8eb33dc1f4", "12373": "86e8b0d2a3533253a7082591f572d73897c02a2c", "12748": "8075887585b0449b6e87ee54c2ca4dbd56960e1e", "14515": "fc0b766ceca487504b040896124a3d809af2975b", "14698": "d13928cc0653f52de55e22118915b0c5bcba13d7", "14725": "34c4908369968dd0f77897ec9dd8c227e7545478", "16940": "bc8666f60f2c8c9ba16b30fbe0b342c3b94213e6", "17074": "68280fb4254b0781a66a1d2689708068799f0bbe", "17075": "b4e8b3ca4366901998c116540902d2687e0a5450", "17279": "518002955b0d6539f8f5e2710b9cefb178cc8ee2", "17645": "d4906939b1ef86657e6617d8fa078a0fbe0c2472", "17934": "2068ff2fd94abe4f14b0334eb4372a64b268f6b4", "19198": "4cc0235ec1ee654ea85cf465d280d33bcb1db20c", "19199": "09dc09a1e9d9088c2cb783c818980f5509d77a11", "19375": "df9f90cfa8795b6d85056f70177fb783d6ecafda", "19504": "bb39b493ef084a4f362d77163c2ca506790c38b6", "19920": "25082e522c90fa9184789f6bc450278b3e18fdda", "20502": "c0c2c737971b52e04b1f6516dfa1bfb05b30f4fd", "20509": "cd12906cabf3576a8c236a4128e959360037dde0", "20952": "918005fd5441650ae4a49b510bcabff69ae898bf", "20955": "b5383488c4b8b97b000585e61ed4e2178fa84d36", "21113": "da4f480a6adf5fed30a42500fe0e5a21c404ac2a", "21126": "82fb053536803f172def9f64e0d62151529173a0", "21322": "2999a2f544cd56575d940d7ab359819b392cccae", "21323": "3c546fd1226a895f68d317d2430daa71fc13e093", "21601": "ea042f1485d5fe45bcf2475c3070cab4e5ac3381", "21602": "51a765acfa4c5d1ec05fc4b406968ad233c75162", "22265": "4d9fab55b9e14e01a7d13344a2612ed802d0c113", "22268": "b687ab371d990373c4a599399172cf31d2f0c350", "22283": "cef2b62701f80ff50a37528b5337dd9a96f0069e", "22393": "38030a00a7f72a3528bd17f2345f34d1344d6d45", "22702": "a5ab948cbc366d705b1f8db8687c7162f51de22d", "23197": "759f4637f9f9471cf4218b9dffc00b464790485b", "23280": "36bc053a69ac5b9ba5a54cb2bd19adb33dcde50e", "23283": "62523372fc6331fc55df73a94d65bfa48c45c193", "23307": "83816c2a95e2ae3c4b3546912de4f4266e0c230f", "23480": "81ba62fe053d56e228ce097cbca91bc5de2e3f82", "23768": "b661a9c81930429cba4a56af291ce2bf8c59f8c9", "24417": "8c439fbe8c340389d7f9d99884180b2e7b21a79f", "24644": "eb6764936c9558553f7a7203a6aaa0ddc6497875", "24809": "f659f5539f9d36ebec4e1d98538919b55299bba4", "25159": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1", "25261": "7389dbac82d362f296dc2746f10e43ffa1615660", "25563": "7b136e92acf49d46251479b75c88cba632de1937", "25750": "ee986788cbd3256f0c36d2ddae155d8ca8f7be1c", "25758": "be2f62b2bfb40747a2dab20f29a341879b247a3c", "25766": "60eb00c72541b42697fa017fdfc74935299fc455", "25767": "93b19b04d3c81f9824b23e1b910126d51f3cd342", "25841": "a243d96336cb4f50ca3635b3062a273f3dc5183a", "25874": "b7b4d3e2f1a65bcb6d40431d3b61ed1d563c9dab", "25910": "e8602bc04e5c7ab32e6acb887b68172098f7f1e2", "26278": "1495f69242646d239d89a5713982946b8ffcf9d9", "26284": "bddd9257f39f190fec3d72872cff73c2b3cc2734", "26819": "db6c12fc117500a751799a3082d1503b65183920", "26820": "e36317b50d70453622ac6d0324a700816bad21c1", "26881": "d39134bc77d9f9a5a0316e21ee32ac3f9683da3d", "26890": "f1f765f476c3cb3e0a882324f8ed67763d76ed26", "26944": "0a56df6dbbe4f1a56cb11d132e43641d7358dd7e", "26953": "5f3c3f0378f2f30f3c4340bd9bf1e211e96d5c3c", "27063": "e5698bde9a8b719514bf39e6e5d58f90cfe5bc01", "27300": "4b7331eeb746b3facb4d70e1760c58ebe8b47f2e", "27325": "daefc22f832177dcbb690369058e0ca776944188", "27498": "a1261a7e18c19bb3dfc8d739a6512c6f671d9e79", "27571": "22a7d5bc722b0430908f202e3ea40aa2ba1a0361", "27604": "483cd3eaa3c636a57ebb0dc4765531183b274df0", "27674": "fd237278e895b42abe8d8d09105cbb82dc2cbba7", "27937": "91a0e4041e6a7ec3752b394956473503e87a5924", "28086": "0fb307bf39bbdacd6ed713c00724f8f871d60370", "28255": "d2cd2540418d3ff66b324ec18566dbe0b5991b40", "28261": "ab3dc9fdf31f35854b390168ac68fb304951305f", "28269": "2828a889bb96f3507ae0b38721d1e37b9f3e553c", "28272": "8b68ea165cb11625254d17c73603c4724d0b6d21", "28277": "74b632a1aa880a9c7f855599d16603626edf97fa", "28278": "28d84693b3855e9a1bf02b61392fb9f31055e897", "28284": "54ce4222694819ad52d544ce5cba5da274c34ab7", "28288": "bc39e62e02b9de82c2a266bb47beac4687843b51", "28291": "df61e9ed98b0777cc0962be6e2d161f4c30110fd", "28296": "13bccedeb02fa650a247a8ab6420bf9d44df3424", "28302": "7ed972193590c2a11839e15db87fa4818089de1a", "28306": "21121f50997dba43fffbfecb2f672431cf708363", "28308": "3bb138f87964dde5f25846f4380afba012cf26bc", "28311": "aa4a10dbfaee9fd52af06f0f0c8e8ae77f243ef6", "28314": "f35457f1fc3282d9efa21a6dc0bfe5a5e8a2f40f", "28320": "58451568d3b44ba632d708add02f9c30f356570a", "28326": "f2635e27894e6fc8c15b13284d3b277dfde65d71", "28333": "3b334c5b257465c5253b5a714eda7b34bc046b45", "28339": "193670c2a17c6a76f852e21cfafb954d195c9d29", "28340": "e6555decf8a72958d26d499deb17aabca41a562a", "28345": "fdb9233f72caec3d3f9720e073b2efdc141847ff", "28347": "1f217f33a25e6033bd0160ee22695186e12e7744", "28357": "cd673475bde70e87255ccd9b6f35687ce59b4b67", "28360": "6ca9eab67e1054a1f9508dfa286e0542c8bab5e3", "28361": "5654da026b7f1186b3a840d1cb140b6598b0af61", "28365": "5d5329c473791c90ebc58b4a18a923d1e6c216b9", "28367": "160debe468890e1dd90b610d5505eb118481cbcf", "28371": "d933c20befea779f9bfd35b4d85adaed9c30d684", "28373": "28f61efad3c4ce6536176978aef0fc857a35ff7b", "28376": "f1111be2fa9899a610843c36d203b0fab02f16c3", "28377": "547feabbb02de7da88bbc692e7b81419e373a0cb", "28381": "dccaf4c867c5ba254b1bd576101d30df40c00760", "28390": "aad222316754a072a893c5e735d4f3f6bd792725", "28392": "8471c8389d794309b0b62a353e3af903acd48223", "28396": "38a50f4c7b429dffeb94ed5abb428da06d0ba859", "28397": "fb67c7bb00f4d68ecbc65e8c46af5372442274cd", "28404": "a2728ac8d4dbc241a997899da61cb0fbf4eec96c", "28413": "4d7e61159db3fb59c474674b3d9f9c656d310e49", "28416": "51acc9dda812efca3c28d97ddc380c421c4949db", "28417": "f0e9d298be351eda7eb7302d6e673b097ae79831", "28418": "b5d63e34746ec273c1cbc5992a0477198a22f8be", "28426": "7db70d5b7988e069088f9956a28f1039e799b709", "28428": "b3806f77895d1146e83fbfdd60c6be43d4a7c144", "28429": "f77fb7265ff9425efb355890107d31012b2c8f33", "28436": "8479a74af207d857da4188b75375ce9d24c7ef90", "28440": "f650d9420bc75e70369fd8c5c96f965b58c0b1d0", "28444": "5a8bbf0195236b2e85217f90c363e5e7f975f157", "28450": "84bd4e29680a9a95ca01143a6ba79a42bc6887ef", "28451": "ffcb869d4b4fc2609b123ac7d089d00791c30f5f", "28453": "b4453f126f34447967f52996039d11b0d2fa0090", "28455": "a85430acdd49b7a63a4de110ee437d092d460d70", "28461": "2f09bbb7eb2fffdffcca3667b8fc38990d3b0893", "28463": "5a09d87da357660f8d16abc2eb424c67db5710c5", "28469": "5fb02bb7bfed1a5edbe12ce942bb77cacde8180b", "28470": "35320845c24ee58a21a99a2df044084e0e65f3a4", "28475": "63d2bbf1ef187d026641514cf511648cedf94701", "28477": "9d394c2daab6df104cef115ebd69f802cc327347", "28482": "eaa45c86f74c41828a92db4d4da2eee643cbda02", "28486": "da562b4fa58bdce4a7f3470f733f33d728747a66", "28488": "fa5f1d5fe3e9a354b32a27a0a24cecef7babebb5", "28496": "59f41f03755fa28495f514a795e19154c0273e35", "28500": "e21319fee78d75e47cacb747aa40b5621f5b04cd", "28502": "2c1719e68e243c71c32c98958cf270a49e7a521f", "28503": "7cb6b8fde70bd12501e85be8102c46b8ca48405f", "28506": "4773f3e39d788e734378f32064cf2e5629fbc7aa", "28507": "c9677d6a7d42aa7162a4c448284b8db1cabde0b0", "28508": "8ebb614a8dc09c7baccb45c6a2cd7d087d8e2ed6", "28511": "0937b4ab48136eb161ead4abd4806d0708b1bb4c", "28517": "95128d3e6d9231703517c732dc73ca8c18adb9d0", "28521": "d304331b450344e4660550b15d8174b15fb616c7", "28525": "be4f8a509f1382a9bbd24194bcfd19c6563fcf31", "28528": "2218ec46227c92301ac6837c4a8ae9b8dc5d3960", "28530": "54375d24a423d77fc5fac1071643a588fc98e818", "28533": "6af03a525c929312f26986f68d3866c217a6838b", "28537": "a92ec1b7582b14fc20e57ffe0c9aa2a00f637766", "28542": "45a817933ef51a24f0c5863c1026b4fe664b26fa", "28548": "6b4f82433dc2f219dbff7fe8fa42c10b72379be6", "28551": "5946f8bfed039540c7527a06f2e6e9f1fb2335c3", "28552": "def0e68085a4339490325dcbfc79143f21ca001e", "28555": "e325bf760f55fb1095a66f1223af2cd396685b2f", "28558": "dfc5e16066b3a3bbf34238cc0f67639d0965f1a8", "28562": "cbfe0ede80beca86750ab8113f17c18c8c8042ce", "28566": "266a11b2e17cf86effefe7b498b61ca31217ad31", "28567": "1e46db669318fe20458d7cf135f6107e19e90970", "28568": "34de1b9b2122783601b245450a1885d18558ac81", "28573": "aa1918cecff1161c36fcf06fa0fe4d1c69ece701", "28576": "be4c1d1fee6ee3ec40935283f9e1ab22ebce27cf", "28581": "0e546ebe5b5a97283ce03f915a83f0d2651394e0", "28583": "9b2a3e8ba50804e5cd1e4302097e86aebd2e8464", "28585": "5a63f903ff1d45084c4fd41f241bf5dfdd067680", "28586": "1fca00b0b46e89956f76e118581a4176888344ab", "28589": "28efdcc5a646fbb8da2456a0f4b8ce7968432242", "28626": "c6512929fbee7232949c0f18cfb28cf3b5959df9", "28630": "e4ae68f09a258d9578f640ff74ca6e209ec37dba", "28632": "9183486463c1df3b5b3c7e2357e17533bdd36573", "28634": "364b1e3e13a48446f86e4682bbf09ba4f010903d", "28640": "8c6a045e46abe94e43a971d4f8042728addfd6a7", "28645": "0f0eb522903431b07f6e267b8b0d42ef24659cbf", "28647": "6f32544c51b43d122dfbed8feff5cd2887bcac80", "28654": "e449f9f1be7dcb937ace1327a4b0c6728afafafa", "28660": "0aee596bb32136df8c68371d696770251c7d14a0", "28664": "c86076fbecaac1f6f5f068a5332871f5dd0f8451", "28668": "ff2e52da0c09e8cb2d9a1b62bd4c3ea481187308", "28671": "b94332434d0117e3d86407560a206d1c7bee1c81", "28674": "38e6022e24e1a3c91f932fec87302ffc0610651b", "28675": "88be2abb7b7f7450dc569e0065e672a0676e4130", "28688": "94b81ab2e7f9b0170b2d6ba6d84c1cc913367d8b", "28689": "50d3aaad36fa83f5d43e8177838726dd08f0526b", "28696": "74a37de119d2c7c9ea1cce673c2ee207541a55d2", "28697": "819c43cc7a1d7efab855e982a91e15be7aec7db1", "28698": "23d8761615d0417eef5f52cc796518e44d41ca2a", "28703": "d6bd7bee8799ea41c456c36a8ccf7780105615e8", "28707": "94337993ef1a29146c67d7e4a51e3053a79e92b7", "28713": "86bc6c9858dd1660f5762003a45733f50fc7a748", "28716": "5403e9fdaee6d4982c887ce2ae9a62ccd3955fbb", "28721": "4aff3857bceb1e42af5ff304140bd4d5b7e74e67", "28728": "6959532d4e43f4434993c027c7b2df09ade942ad", "28735": "dac560551c5767d9a8608f86e3f253e706026189", "28738": "b251f3f818e8d3cdb7ef843006d19da87755d444", "28741": "4d60a815d84531ba91bf097e9c814460113a7b72", "28749": "e9c6fcaa17b983858400465fd39a2616c980c3db", "28752": "b5e55f79fdfcb0f41f0cfb279e54a123822bca43", "28754": "70c6ac9d04c396faaf604c2fd1d3945f25e4d6d4", "28762": "26c5530e792c1319ddd3335e23d1f36cf90f6c3d", "28765": "e23dd851476ef54c2153d6178500a3e2345f95b4", "28768": "638b7689bbbfae4bcc4592c6f8a43ce86b571f0b", "28776": "94abe05b4b96de2ca30d998fb9adb2fbd3eb1bde", "28780": "15c2c72e27c6ea18566f4e786506c7a3aef8a5de", "28783": "72db93cc40884f42e05e4290d6ab63713d0075c9", "28787": "28ee486b44f8e7e6440f3439e7315ba1e6d35e43", "28790": "1045d16ec13b1cab7878e7555538573d1884aad3", "28791": "42e90e9ba28fb37c2c9bd3e8aed1ac2387f1d5d5", "28792": "f2773e840a0fcc9dd673cdd0da82dc43299a713b", "28793": "ae3d955c90d03479d4b6a8a3b359fba10826dc2a", "28795": "4beb0c27fc0439c12dad244fe4063e96f8983a52", "28798": "6f180d79f58b42a3fa06055c489b1edf857399ff", "28802": "15fd026963be233d37752f322b5dd484c58e09a8", "28803": "f4e692c0876425ef6afb6f514b54696f3e071c35", "28805": "0c74b8b7d5cdb60dc3a3240cdb36af40b9f40288", "28809": "302106bcac4476ecdd76b8c03fddb454edbcad96", "28812": "b7b510f9dbc87500e79301873852c6247c440a3e", "28818": "04f84c6d082864c208682d27256ff74b7b488734", "28821": "0d7d46f3bef0a2f943ee321f0f979ced165e0477", "28828": "266400e60ddc0bdba1f0de02ed49f45893e5647c", "28830": "3e45aeef901871b84ce59709e62f3d2245463cd8", "28835": "81102146e35c81d7aab16d448f1c2b66d8a67ed9", "28841": "114616d9f6ce9eba7c1aacd3d4a254f868010e25", "28842": "4dfdfb4e1bb3719628753a4ece995a1b2fa5312a", "28852": "f0576399d9cfb41c1f3cd4a0a2332578b1c0b573", "28854": "f47926999d35686ff2190c3940c82d7cc7f3e691", "28856": "c957eb37b5988e6e2a4692c1356e8689294404c5", "28860": "9cfacf1540a991461b91617c779c69753a1ee4c0", "28862": "36c635b77f9744b627248f96f15f3e73e97d3571", "28868": "132627e28b5be807b1e4b7d58bedf42b529d7800", "28879": "3ff1267a7b74259dd0f0fdaf7da88b02e727e7c1", "28880": "b1d686d07559fb83040cb085b752d86ebbb9b3ba", "28884": "c09c654ed4d5833d73f557381f3d10f3d062e5d7", "28891": "7fa2e6e2734b590d96e62d5932c648a9c1002f34", "28894": "138da7ea911274f34d28849337c2768d7e3a7a96", "28896": "2c5ea4e6b3add57588fb35293b7dd25506c5fe06", "28899": "e1f879e8eed85c5018d888c9f87f168bc44085e1", "28906": "0df9efe2c1407f3fb887c22056452c791fd83dc9", "28915": "004b44d007408aa2db1fdaf4428990d0d7b7f85a", "28918": "a67b284f90299989c4cc03f848dc9cc1be57c623", "28921": "c88c89cffd87c34299ebb8db6192c973823bd827", "28923": "2641baf16d9de5191316745ec46120cc8b57a666", "28929": "e4bb9fa86b0df873ad750b6d59090843d9d23d50", "28937": "a45c0c99a38cffca6724cb8fd38b12edd4fb6b35", "29085": "15a949460dbf19e5e196b8ef48f9712b72a3b3c3", "29086": "a9cc0ed86fca1480acbd8aaf211f062ee2abd5b7", "29089": "9c3b402f0082cfc17da3ab9430a203ecc2ac4dfc", "29091": "4023a0f94bde429456f45b983c84c5f35475480f", "29093": "a9ce392f3a58da5caf5ac9bd287205e220082fc5", "29095": "0eb9ad73c53c8f3cc0ea03d33312035853bee29b", "29096": "de1262c35e2aa4ee062d050281ee576ce9e35c94", "29101": "2bd3a4db529d707a9862d69cc1ddbcbe7a6054b8", "29110": "847fc6a27431d96eaef926773608168e8edb9e12", "29112": "48ab1bf71aea9b7036108179e00e0b2e1c3fcf7e", "29113": "f6e6ad2d9e9172c55c778392b27b69c6af87bd98", "29114": "5073d692f04dea88d595252a6cc0382509b6947d", "29115": "d73822f84f2832dcc25f0ff58769f60871a78025", "29117": "053d2d1af477d9dc17e69162b9f2298c0fda5905", "29128": "ca6caa28ab92cbf75a3cc2a411d2a225abd9a4ce", "29132": "1ac047d29a43bd1556d5c90e40376340a08bc3a6", "29134": "c67518350f91072f9d37ed09c5ef7edf555b6cf6", "29136": "36a4dcafedbcbb112e1d96fd04e73ba922523bae", "29138": "aa898de885ed4861a03e4f79b28f92f70914643d", "29139": "5b7136f04068e7dcdf5ae8ec4aa729107ee905c0", "29141": "c1cc67dd06d31a9b110377afe0c94b0cd50848d5", "29167": "7c873713df056a9554dd545b0d5f0be93630219b", "29174": "c9d223ccc58e2569b8e67f1d0217dd57a93ec07f", "29178": "deda6e2a5a01ad22096862bded5f66e9578cc39e", "29182": "7bb3e22b3c454a59619a56c314be04b4b303e09a", "29192": "6850c04186b88e88e9c8cd6eb673721af806e3da", "29193": "5d25ce13ae0fa8f1f9e02d046d1820b6dcfd6155", "29200": "1038024a438e2bc76e7e48edde7b7ca732dc506b", "29216": "1cd282d600088d2547d827af72a99e036106417a", "29221": "038c5cd04558e572b6a4dea7383a515ff10090e5", "29225": "9a13bdfaf1a47188d2e1262f0308f317e6662e8d", "29226": "b5e5db4a43e9f79d877a0d88ba94392925981b31", "29239": "0eeebb1e3d59f739f6eb9319ceb254a8486493d5"}, "revision_to_date": {"382": 1264603663000, "395": 1265024295000, "587": 1269007740000, "590": 1269244318000, "646": 1270698297000, "745": 1272878771000, "755": 1272909852000, "811": 1273294444000, "813": 1273337313000, "826": 1273550555000, "998": 1277561666000, "1016": 1277824675000, "1131": 1279558872000, "1207": 1280235748000, "1288": 1281104090000, "1915": 1286358759000, "1917": 1286371631000, "1919": 1286373337000, "1969": 1286782666000, "1977": 1286812002000, "2701": 1292596297000, "2711": 1292968871000, "2743": 1294669325000, "3102": 1298808434000, "3151": 1299078131000, "3212": 1299680572000, "3289": 1300670714000, "3741": 1302729559000, "3905": 1304345121000, "4037": 1305108339000, "4054": 1305126138000, "4684": 1309505367000, "4696": 1309545528000, "6177": 1316527045000, "6225": 1316642399000, "6511": 1318977607000, "7872": 1326216418000, "7904": 1326287141000, "7919": 1326426441000, "9331": 1336328405000, "9349": 1336407543000, "9357": 1336426836000, "9369": 1336524866000, "9799": 1341415689000, "10413": 1346780365000, "10436": 1346788092000, "10457": 1346981442000, "10778": 1349734773000, "12368": 1358801181000, "12373": 1358806382000, "12748": 1361636276000, "14515": 1375060310000, "14698": 1375915741000, "14725": 1375972053000, "16940": 1401972588000, "17074": 1404172403000, "17075": 1404240383000, "17279": 1405354512000, "17645": 1406899808000, "17934": 1409835738000, "19198": 1425667359000, "19199": 1425681522000, "19375": 1427396256000, "19504": 1429027572000, "19920": 1436588422000, "20502": 1445007457000, "20509": 1445013082000, "20952": 1445953225000, "20955": 1445958667000, "21113": 1446753465000, "21126": 1446818031000, "21322": 1450749753000, "21323": 1450761225000, "21601": 1455802186000, "21602": 1455802246000, "22265": 1473791605000, "22268": 1473799038000, "22283": 1473882154000, "22393": 1475007587000, "22702": 1478902517000, "23197": 1497903977000, "23280": 1499947923000, "23283": 1499952302000, "23307": 1500281648000, "23480": 1502470027000, "23768": 1505921382000, "24417": 1531668719000, "24644": 1535551327000, "24809": 1537887812000, "25159": 1542875805000, "25261": 1545209521000, "25563": 1551431215000, "25750": 1556378170000, "25758": 1556603560000, "25766": 1556634531000, "25767": 1556635319000, "25841": 1557442357000, "25874": 1557893876000, "25910": 1558616196000, "26278": 1564406958000, "26284": 1558572641000, "26819": 1573637668000, "26820": 1573476950000, "26881": 1574093837000, "26890": 1574244189000, "26944": 1574933073000, "26953": 1575301264000, "27063": 1577976510000, "27300": 1582908441000, "27325": 1583315487000, "27498": 1588010313000, "27571": 1588689638000, "27604": 1589270282000, "27674": 1589872045000, "27937": 1593854670000, "28086": 1592994930000, "28255": 1599747257000, "28261": 1600274505000, "28269": 1600378277000, "28272": 1600458232000, "28277": 1600722669000, "28278": 1600789062000, "28284": 1600865667000, "28288": 1600968970000, "28291": 1601106935000, "28296": 1601326769000, "28302": 1601415150000, "28306": 1601462345000, "28308": 1601589341000, "28311": 1601660413000, "28314": 1601930618000, "28320": 1602017230000, "28326": 1602089300000, "28333": 1602190160000, "28339": 1602263563000, "28340": 1602436405000, "28345": 1602536302000, "28347": 1602591864000, "28357": 1602693776000, "28360": 1602796581000, "28361": 1602859901000, "28365": 1603135307000, "28367": 1603210848000, "28371": 1603296704000, "28373": 1603378269000, "28376": 1603484187000, "28377": 1603729650000, "28381": 1603813015000, "28390": 1603918365000, "28392": 1603993849000, "28396": 1604082959000, "28397": 1604157689000, "28404": 1604266317000, "28413": 1604338820000, "28416": 1604443088000, "28417": 1604518746000, "28418": 1604585464000, "28426": 1604687645000, "28428": 1604867994000, "28429": 1604916743000, "28436": 1605029333000, "28440": 1605135329000, "28444": 1605211856000, "28450": 1605292115000, "28451": 1605376572000, "28453": 1605564612000, "28455": 1605628238000, "28461": 1605722026000, "28463": 1605822301000, "28469": 1605911343000, "28470": 1606015242000, "28475": 1606161074000, "28477": 1606336705000, "28482": 1606416080000, "28486": 1606497935000, "28488": 1606765444000, "28496": 1606821855000, "28500": 1606925797000, "28502": 1606931617000, "28503": 1607004204000, "28506": 1607116223000, "28507": 1607613543000, "28508": 1607723835000, "28511": 1607961058000, "28517": 1608059116000, "28521": 1608136519000, "28525": 1608242770000, "28528": 1608307759000, "28530": 1608395895000, "28533": 1608486943000, "28537": 1608587907000, "28542": 1608647213000, "28548": 1608676289000, "28551": 1609623728000, "28552": 1609698314000, "28555": 1609772780000, "28558": 1609840352000, "28562": 1609944537000, "28566": 1610128553000, "28567": 1610214433000, "28568": 1610304129000, "28573": 1610387413000, "28576": 1610461836000, "28581": 1610553773000, "28583": 1610641692000, "28585": 1610821727000, "28586": 1610915313000, "28589": 1610996785000, "28626": 1611052138000, "28630": 1611096802000, "28632": 1611164131000, "28634": 1611255467000, "28640": 1611341861000, "28645": 1611414840000, "28647": 1611487810000, "28654": 1611614513000, "28660": 1611689734000, "28664": 1611786407000, "28668": 1611868041000, "28671": 1611929245000, "28674": 1612010107000, "28675": 1612054336000, "28688": 1612217026000, "28689": 1612286029000, "28696": 1612393433000, "28697": 1612446975000, "28698": 1612514236000, "28703": 1612635631000, "28707": 1612696745000, "28713": 1612872626000, "28716": 1612885946000, "28721": 1612981796000, "28728": 1613076767000, "28735": 1613159543000, "28738": 1613400754000, "28741": 1613569280000, "28749": 1613674543000, "28752": 1613731449000, "28754": 1613840479000, "28762": 1614025369000, "28765": 1614104321000, "28768": 1614147824000, "28776": 1614262574000, "28780": 1614447340000, "28783": 1614618476000, "28787": 1614683996000, "28790": 1614793397000, "28791": 1615128856000, "28792": 1615226636000, "28793": 1615308357000, "28795": 1615382782000, "28798": 1615484044000, "28802": 1615590149000, "28803": 1615592700000, "28805": 1615733031000, "28809": 1615834814000, "28812": 1615930546000, "28818": 1615992780000, "28821": 1616089367000, "28828": 1616186648000, "28830": 1616249229000, "28835": 1616353572000, "28841": 1616519345000, "28842": 1616701156000, "28852": 1617400845000, "28854": 1617566024000, "28856": 1617640124000, "28860": 1617737608000, "28862": 1617832061000, "28868": 1617916880000, "28879": 1617992344000, "28880": 1618175593000, "28884": 1618257581000, "28891": 1618347639000, "28894": 1618413717000, "28896": 1618490002000, "28899": 1618600033000, "28906": 1618868919000, "28915": 1618954142000, "28918": 1619040868000, "28921": 1619110246000, "28923": 1619178650000, "28929": 1619467448000, "28937": 1619544136000, "29085": 1619600857000, "29086": 1619617061000, "29089": 1619725616000, "29091": 1619739533000, "29093": 1620050725000, "29095": 1620244799000, "29096": 1620265097000, "29101": 1620677421000, "29110": 1620770403000, "29112": 1620920636000, "29113": 1621006227000, "29114": 1621032016000, "29115": 1621172982000, "29117": 1621241554000, "29128": 1621364951000, "29132": 1621431262000, "29134": 1621520828000, "29136": 1621605580000, "29138": 1621709722000, "29139": 1621878405000, "29141": 1621944157000, "29167": 1622043901000, "29174": 1622124056000, "29178": 1622233878000, "29182": 1622489783000, "29192": 1622582567000, "29193": 1622648501000, "29200": 1622728054000, "29216": 1623250683000, "29221": 1623445015000, "29225": 1623510849000, "29226": 1623544407000, "29239": 1623793687000}, "params": {"arch": ["x86_64"], "cpu": ["Intel Core Processor (Haswell, no TSX)"], "machine": ["sklearn-benchmark"], "num_cpu": ["8"], "os": ["Linux 4.15.0-20-generic"], "ram": ["16424684"], "python": ["3.8"], "numpy": [""], "scipy": [""], "cython": [""], "joblib": [""], "threadpoolctl": [""], "branch": ["main"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel Core Processor (Haswell, no TSX)", "machine": "sklearn-benchmark", "num_cpu": "8", "os": "Linux 4.15.0-20-generic", "ram": "16424684", "python": "3.8", "numpy": "", "scipy": "", "cython": "", "joblib": "", "threadpoolctl": "", "branch": "main"}], "benchmarks": {"cluster.KMeansBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_fit", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "44996b30a90296496e9fbd453654a32aa6c2909019acefc1ecae8d8eb4609d15"}, "cluster.KMeansBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_predict", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "510a8c6e9aad0a40d0f8a0b5e80a5e07f0d8151c5efce1d37b2fc63c39bb32e5"}, "cluster.KMeansBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_transform", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "70a2cb80848550589a4507ca5a90210a9df9621d3fbe9a665f3fe215d263ac25"}, "cluster.KMeansBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_fit", "number": 0, "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "a7f0a87fd088d4fcaf9d60644c6c653c75d1261c10be350e2ad325cbbade2aaf", "warmup_time": 1}, "cluster.KMeansBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_predict", "number": 0, "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "75e2bf5cab4c55598df2a5964235bb56158f1fd58fbe88037bbeb27518941430", "warmup_time": 1}, "cluster.KMeansBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_transform", "number": 0, "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "e89a4fa90042114d4904732525795519e353e717562e734ef51e1a17fdb37ee2", "warmup_time": 1}, "cluster.KMeansBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.track_test_score", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "track", "unit": "unit", "version": "3c3af2849d342cebc878a7ac97ad167c9db632ac6e72ee902c1f0def6ef488b8"}, "cluster.KMeansBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.track_train_score", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'full'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "track", "unit": "unit", "version": "0b1413310939b67bdbb6490a3b9ccc19d0f4bf68615214df8463596abc27cd29"}, "cluster.MiniBatchKMeansBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.peakmem_fit", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:63", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "27a823a52563653b94cee28aee3234581dfdc555a0360637498b08166bc1d9ad"}, "cluster.MiniBatchKMeansBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.peakmem_predict", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:63", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "41369a0e02bed31162a08bdf8f5fa2bac1ece3644dd88e977837dc5ebfc9449c"}, "cluster.MiniBatchKMeansBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.peakmem_transform", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:63", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "3809620b44698eaa55ea358f5867374ef6b4f0dc3b7b3fb2bd28de40db441d22"}, "cluster.MiniBatchKMeansBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.MiniBatchKMeansBenchmark.time_fit", "number": 0, "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:63", "timeout": 500, "type": "time", "unit": "seconds", "version": "f3fda2b1a621d39ede4bc2103dede0fde92fbd210d39d015ea61934bfccfc7c2", "warmup_time": 1}, "cluster.MiniBatchKMeansBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.MiniBatchKMeansBenchmark.time_predict", "number": 0, "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:63", "timeout": 500, "type": "time", "unit": "seconds", "version": "23ec70517acd7b8eba2cdc3cc9c57604c51b5639b32fffc729a4f20a24b06d72", "warmup_time": 1}, "cluster.MiniBatchKMeansBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.MiniBatchKMeansBenchmark.time_transform", "number": 0, "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:63", "timeout": 500, "type": "time", "unit": "seconds", "version": "80d12f75cd37166bced2570d27f5250389ec6f7df8982e734288778fa0067280", "warmup_time": 1}, "cluster.MiniBatchKMeansBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.track_test_score", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:63", "timeout": 500, "type": "track", "unit": "unit", "version": "b15e6712b29288eb2cf5fc5bd336054544a9002dfab16a6e299d6f992154edc9"}, "cluster.MiniBatchKMeansBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.track_train_score", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:63", "timeout": 500, "type": "track", "unit": "unit", "version": "858db1057ab8f972235963a5c0e46e44c848881c70c927afddb64243168000b0"}, "decomposition.DictionaryLearningBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.peakmem_fit", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:44", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "190e4b8153b3607376247c0a64f4c1d8aa385789d8f2eb6e65be2006fc0f21a0"}, "decomposition.DictionaryLearningBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.peakmem_transform", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:44", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "b5d9d222d5acbb1ba622ed388de04f7bc205f57e0ec5112c0792edad34ad712a"}, "decomposition.DictionaryLearningBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.DictionaryLearningBenchmark.time_fit", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:44", "timeout": 500, "type": "time", "unit": "seconds", "version": "3b1cb33cf7cae38b9084e69ee8840abd4a0209018cf63db5ae6d22e2915ecc04", "warmup_time": 1}, "decomposition.DictionaryLearningBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.DictionaryLearningBenchmark.time_transform", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:44", "timeout": 500, "type": "time", "unit": "seconds", "version": "78044cbc0c8ef76c735aecaaee722df32400100fd621a5cb73d6207aad3736e8", "warmup_time": 1}, "decomposition.DictionaryLearningBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.track_test_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:44", "timeout": 500, "type": "track", "unit": "unit", "version": "dffe185efa679099c300a200d5f1548d7025bb14150cc130ee9594dbca6a08f4"}, "decomposition.DictionaryLearningBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.track_train_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:44", "timeout": 500, "type": "track", "unit": "unit", "version": "e132e82fb0e747524994e89713ee6cc7c16e11ac696381769ba0b7a865f809ee"}, "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_fit", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "7413c15d31d1af9d57b047e1eb9793e8fd9442dd4852f9bbf7944520b6cde539"}, "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_transform", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "9583e478652b4aa7adf26052264d261ed51218bfb02c392a8dd5afa6f0be9067"}, "decomposition.MiniBatchDictionaryLearningBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.MiniBatchDictionaryLearningBenchmark.time_fit", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:75", "timeout": 500, "type": "time", "unit": "seconds", "version": "fbedaca37b514fdecdc98bf0d5e99cc18f4e81adafa0501bf2cb62b395cff80b", "warmup_time": 1}, "decomposition.MiniBatchDictionaryLearningBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.MiniBatchDictionaryLearningBenchmark.time_transform", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:75", "timeout": 500, "type": "time", "unit": "seconds", "version": "04e8b945e21dc8f7471c0bb5d123098da806565bcd07f0ae5c78c42492669af1", "warmup_time": 1}, "decomposition.MiniBatchDictionaryLearningBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.track_test_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "track", "unit": "unit", "version": "3254255804120abf8154e7fb27ecc492ebf763052bc0b660de4ae3579648a704"}, "decomposition.MiniBatchDictionaryLearningBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.track_train_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "track", "unit": "unit", "version": "68f98a3244c8ad2dec8817d68a45e5c8185c6b2487bca85e5302d103e6bdf725"}, "decomposition.PCABenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.peakmem_fit", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "42a67cdbc3312242272375647a4c8921d248f3932a1f45439cd1ee6fb5bfa1ac"}, "decomposition.PCABenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.peakmem_transform", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "7d07701a485134ed88af807935021a90621db5698a9246bc6da7a2088a7f79c2"}, "decomposition.PCABenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.PCABenchmark.time_fit", "number": 0, "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:17", "timeout": 500, "type": "time", "unit": "seconds", "version": "0cbc79d745e8e837e60d0fb6ce4c28d169a4f3d0374aa4c41c1af06f20fd00ae", "warmup_time": 1}, "decomposition.PCABenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.PCABenchmark.time_transform", "number": 0, "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:17", "timeout": 500, "type": "time", "unit": "seconds", "version": "32433581033fb7c58370c65de59d3bc16af930d20e4b5b1de444aa4cf264b1f1", "warmup_time": 1}, "decomposition.PCABenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.track_test_score", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "track", "unit": "unit", "version": "76c2fa737efe3334a87e39743a537297128e25318011c3e3ffec6d548f265b4c"}, "decomposition.PCABenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.track_train_score", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:17", "timeout": 500, "type": "track", "unit": "unit", "version": "6a4bc757dc7f536b1ff12965462bc10eb7e03fb3f1d3a4c93284b35cfc4eb488"}, "ensemble.GradientBoostingClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:58", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "cc97dee1993c6d12e78438319cd9469d26f81a43f7938e1c6008b3953a2bd7ad"}, "ensemble.GradientBoostingClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:58", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "5f33dca7623ebcf5b9da857840f38d4160d0eefbdfaaae93a0df0eff427c1d84"}, "ensemble.GradientBoostingClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.GradientBoostingClassifierBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:58", "timeout": 500, "type": "time", "unit": "seconds", "version": "0d76a561d7d93f238535f79890799de6081b98af1b48172ec072d9f35a80c556", "warmup_time": 1}, "ensemble.GradientBoostingClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.GradientBoostingClassifierBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:58", "timeout": 500, "type": "time", "unit": "seconds", "version": "07e35a379ff33d5642a8e688571b88abaa50f49959b22447600813915b18f5f5", "warmup_time": 1}, "ensemble.GradientBoostingClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:58", "timeout": 500, "type": "track", "unit": "unit", "version": "5aa3692fb65a37ed9286c6ea97af19db99c401629673d6ebcb9a847fb0f50b3d"}, "ensemble.GradientBoostingClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:58", "timeout": 500, "type": "track", "unit": "unit", "version": "61a34f67a5943b1efa1968705ece7be5cd9e97fba27bc7a42ca9a5e61f07eb52"}, "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_fit", "param_names": [], "params": [], "setup_cache_key": "ensemble:95", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "92579826177c3d6d7beb1475a3ad1683b67326ee979d80d34256a06c54444a85"}, "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_predict", "param_names": [], "params": [], "setup_cache_key": "ensemble:95", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "4119f79ee2410f297720ebbe804f68573fe7065a9b3ca92e2eb2a40f840ea68b"}, "ensemble.HistGradientBoostingClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.HistGradientBoostingClassifierBenchmark.time_fit", "number": 0, "param_names": [], "params": [], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:95", "timeout": 500, "type": "time", "unit": "seconds", "version": "cd73e526a2442477e22de2f22d552e2498295e53ea583cfefb033d880fd7e2f2", "warmup_time": 1}, "ensemble.HistGradientBoostingClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.HistGradientBoostingClassifierBenchmark.time_predict", "number": 0, "param_names": [], "params": [], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:95", "timeout": 500, "type": "time", "unit": "seconds", "version": "4b5ba50a87ee05617a815e1a4f3a0f77bdf656edd6aa400956fdcb17f8848e18", "warmup_time": 1}, "ensemble.HistGradientBoostingClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.track_test_score", "param_names": [], "params": [], "setup_cache_key": "ensemble:95", "timeout": 500, "type": "track", "unit": "unit", "version": "65c33a87df35a03d1f077135b163fcf8a525f5145281b743f5dde67be9d93352"}, "ensemble.HistGradientBoostingClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.track_train_score", "param_names": [], "params": [], "setup_cache_key": "ensemble:95", "timeout": 500, "type": "track", "unit": "unit", "version": "81f771d004b7edd4af37042b13e8aef59fcb83f09b3c317d6d635fbf5005038a"}, "ensemble.RandomForestClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.peakmem_fit", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "55af394470ec69b30129fd9983d4402432d1148dfe0d1c5e8fe57a066313c5bc"}, "ensemble.RandomForestClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.peakmem_predict", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "e92c3b611bdc16c763e9fc9210e3850aa3ae5b7230677c2f03a6e1e267ca41c5"}, "ensemble.RandomForestClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.RandomForestClassifierBenchmark.time_fit", "number": 0, "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "1c07b253be62fce0a4828c260541f370c60bf286df1079e5a868f1597a7ba403", "warmup_time": 1}, "ensemble.RandomForestClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.RandomForestClassifierBenchmark.time_predict", "number": 0, "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "336d398a53cc6c24a3f37b2493ede95c50fd9bae5093bb07b8bb6f044324dfdd", "warmup_time": 1}, "ensemble.RandomForestClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.track_test_score", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:20", "timeout": 500, "type": "track", "unit": "unit", "version": "e14fd390f6da53ec6b8c47fb1eee7139ed1b66de7f6491e051941aac2dd3b416"}, "ensemble.RandomForestClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.track_train_score", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:20", "timeout": 500, "type": "track", "unit": "unit", "version": "e7cd145fca061e4cc80f6e9b17a7beb2465360102c477407540fe4b86bf129a4"}, "linear_model.ElasticNetBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.peakmem_fit", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:175", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "28c73acbc0d080902bd2724f4acba17ae53a5d446c766f31c8f7d6b4bcdf795a"}, "linear_model.ElasticNetBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.peakmem_predict", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:175", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "f15eca10627e9e0918ddceeaa1a7ec5b66c48d8267d639d16cd7cca7c845ce3b"}, "linear_model.ElasticNetBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.ElasticNetBenchmark.time_fit", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:175", "timeout": 500, "type": "time", "unit": "seconds", "version": "51ff64daecf6ce6464125feebc7b0f40fb4ac09f6ae76a51c92b7c877ae4dabe", "warmup_time": 1}, "linear_model.ElasticNetBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.ElasticNetBenchmark.time_predict", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:175", "timeout": 500, "type": "time", "unit": "seconds", "version": "91b770a9ba1111b5b98d34b3ec3b6e4272bfb7973c727b829eff4898b1317e6f", "warmup_time": 1}, "linear_model.ElasticNetBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.track_test_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:175", "timeout": 500, "type": "track", "unit": "unit", "version": "32f80b46b3e70b4627de35a21f0a5891e2a74b77490a980b894f315f8f8a23a7"}, "linear_model.ElasticNetBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.track_train_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:175", "timeout": 500, "type": "track", "unit": "unit", "version": "9d8f3476eeeb0674e29f4482a82870ef1c00638cc9294584483e6b1a0505a07d"}, "linear_model.LassoBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.peakmem_fit", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:218", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "b0dadfa535e73bb2d13461ca245f512953fbb93f299bc95c3459302652b07d6b"}, "linear_model.LassoBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.peakmem_predict", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:218", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "731893e0b12c495801aa4592439c25dfa6e134813acaf875d0223d967a2cb844"}, "linear_model.LassoBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LassoBenchmark.time_fit", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:218", "timeout": 500, "type": "time", "unit": "seconds", "version": "a0883a2adc4f493a8127a070e4bf142445948779c7cdddbdcd6d163259d20796", "warmup_time": 1}, "linear_model.LassoBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LassoBenchmark.time_predict", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:218", "timeout": 500, "type": "time", "unit": "seconds", "version": "08cca0bd03f7ac27ebdeb7e683e362c63a114b746b4ea44149df04f08441812e", "warmup_time": 1}, "linear_model.LassoBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.track_test_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:218", "timeout": 500, "type": "track", "unit": "unit", "version": "2cb69e90fe3348aa8163d5702f21dc704e90321c3193fd397e25cb9a3a80f2c4"}, "linear_model.LassoBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.track_train_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:218", "timeout": 500, "type": "track", "unit": "unit", "version": "530ae6319b705e1b7b9c8653b28f83d6d7556309c83fedffe99aa23a8ca63633"}, "linear_model.LinearRegressionBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:109", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "fded6cdb7544c9b687b7393fc5ade04b42d1b6150d4412708c27ee97037338be"}, "linear_model.LinearRegressionBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:109", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "7e91327ad48684b6bc6161727401f32e004fe4ded945a7e7d9a9320a370ceaa7"}, "linear_model.LinearRegressionBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LinearRegressionBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:109", "timeout": 500, "type": "time", "unit": "seconds", "version": "b16188fca72aa0564f45e39b075510d1e2afa784e3ad92a1bd2c97dbbdd8c7dd", "warmup_time": 1}, "linear_model.LinearRegressionBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LinearRegressionBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:109", "timeout": 500, "type": "time", "unit": "seconds", "version": "bd7cb5a02ebdd3cfc557cdcaa7d2d4ce386faac4ef90b850c55df3cf2ec6acbc", "warmup_time": 1}, "linear_model.LinearRegressionBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:109", "timeout": 500, "type": "track", "unit": "unit", "version": "cca172d913657c29eab5cb151a16a436bcbce59f2fa0b45f974a4f81a20ea922"}, "linear_model.LinearRegressionBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:109", "timeout": 500, "type": "track", "unit": "unit", "version": "e328cc796a311efd30fd79e4fd9872c08320937dca931c4071d34608d6fec18f"}, "linear_model.LogisticRegressionBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.peakmem_fit", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "227b880c2ee8b9c108b7a50950b3a603b2dc40e4cabc7cb4477855a83667b09d"}, "linear_model.LogisticRegressionBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.peakmem_predict", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "df044eb5a9c17b37de661eaef6893198a3487e81520a885b94ef03240ef8837b"}, "linear_model.LogisticRegressionBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LogisticRegressionBenchmark.time_fit", "number": 0, "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "3d4beec90f283c2cbd19a02606f3f7854814c69806ea71019959604a4d39a9d3", "warmup_time": 1}, "linear_model.LogisticRegressionBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LogisticRegressionBenchmark.time_predict", "number": 0, "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:20", "timeout": 500, "type": "time", "unit": "seconds", "version": "6f2562b5f8d268cf7055e64b940013860706e65b134f84e32339f5875723eda2", "warmup_time": 1}, "linear_model.LogisticRegressionBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.track_test_score", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "track", "unit": "unit", "version": "3188fa6ed863c4941526dc4155a91de5770e1323ec73aa4a230cec942097b2d5"}, "linear_model.LogisticRegressionBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.track_train_score", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:20", "timeout": 500, "type": "track", "unit": "unit", "version": "8eda4a42bdf21139b9ebe1f71eacdac69f314f14a2d35caacbba7286481392c2"}, "linear_model.RidgeBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.peakmem_fit", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:66", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "0fb7961b46be1655cff5ec1cc08fc925fd173710418d9a31fb5b0a56b428303d"}, "linear_model.RidgeBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.peakmem_predict", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:66", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "919b8ad2aa4dce054f744439add082932e11625a2bb6f274a5f5c190f5d74ee0"}, "linear_model.RidgeBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.RidgeBenchmark.time_fit", "number": 0, "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:66", "timeout": 500, "type": "time", "unit": "seconds", "version": "8a363dc27cdb675a4c9fc87ded4ffc43d0d06b9e73e786cb2d945c7c170917e5", "warmup_time": 1}, "linear_model.RidgeBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.RidgeBenchmark.time_predict", "number": 0, "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:66", "timeout": 500, "type": "time", "unit": "seconds", "version": "6c702677952dfcf9626c6abec5f29d6cb4d5f7c833e6d66d0167375a17d8f911", "warmup_time": 1}, "linear_model.RidgeBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.track_test_score", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:66", "timeout": 500, "type": "track", "unit": "unit", "version": "b1e2308ac9f2bfe08840f9c17838fd74aef28ffaf207ed8c20d96bdb6cb2b58f"}, "linear_model.RidgeBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.track_train_score", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:66", "timeout": 500, "type": "track", "unit": "unit", "version": "e96065aa177f3ef7660e8b1c5d33903d198a160073bb32bae3bf31859fb790e2"}, "linear_model.SGDRegressorBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:141", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "68b98e0f1064163a34bc0578aa1cec92de65faceac2c895a43dc0fe28f277183"}, "linear_model.SGDRegressorBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:141", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "813f1a9f4e78a8f537c3da3011432175c068f46d5f99e084797f793bb2ce0c71"}, "linear_model.SGDRegressorBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.SGDRegressorBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:141", "timeout": 500, "type": "time", "unit": "seconds", "version": "0746a9008d18b05e045f4be5c1fc1495f4ff577234636923a65172909250f277", "warmup_time": 1}, "linear_model.SGDRegressorBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.SGDRegressorBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:141", "timeout": 500, "type": "time", "unit": "seconds", "version": "92c45304d728e9fc68e0ad075acfab2527c012c257f1138fdc90becf644bddce", "warmup_time": 1}, "linear_model.SGDRegressorBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:141", "timeout": 500, "type": "track", "unit": "unit", "version": "e15ee5db5de8aa8755ff4c59edd3ebea7317e15e47b4b960e8af6644fed1eed9"}, "linear_model.SGDRegressorBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:141", "timeout": 500, "type": "track", "unit": "unit", "version": "7732977fb570e6e6e5cc0fe2b8270dc2ce9ee4e0c50fac00d102e91072f3fcf3"}, "manifold.TSNEBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.peakmem_fit", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "68f2ed8a98bbd0198abf7ccece495dede3db25c40073344d4ff26a8921d25d09"}, "manifold.TSNEBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "manifold.TSNEBenchmark.time_fit", "number": 0, "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "manifold:15", "timeout": 500, "type": "time", "unit": "seconds", "version": "0bc09923597164ea9b4351cdbede223850c7012f81b646429e3637ea2b4fc222", "warmup_time": 1}, "manifold.TSNEBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.track_test_score", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "track", "unit": "unit", "version": "082788471a14e89a238c8e6f4bb3d5ea740773a3474b446f642868f9bad812c2"}, "manifold.TSNEBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.track_train_score", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "track", "unit": "unit", "version": "ea38ad09ca9102953d5956c98df7dc58fbd07b38685c6d31ce41db07c81c00b7"}, "metrics.PairwiseDistancesBenchmark.peakmem_pairwise_distances": {"code": "class PairwiseDistancesBenchmark:\n    def peakmem_pairwise_distances(self, *args):\n        pairwise_distances(self.X, **self.pdist_params)\n\n    def setup(self, *params):\n        representation, metric, n_jobs = params\n    \n        if representation == 'sparse' and metric == 'correlation':\n            raise NotImplementedError\n    \n        if Benchmark.data_size == 'large':\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 8000\n            else:\n                n_samples = 24000\n        else:\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 4000\n            else:\n                n_samples = 12000\n    \n        data = _random_dataset(n_samples=n_samples,\n                               representation=representation)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.pdist_params = {'metric': metric,\n                             'n_jobs': n_jobs}", "name": "metrics.PairwiseDistancesBenchmark.peakmem_pairwise_distances", "param_names": ["representation", "metric", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'cosine'", "'euclidean'", "'manhattan'", "'correlation'"], ["1", "4"]], "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "9e233ad5c2450fe03927e9610c457ce1c967b83279fe878e2280101e3e1ae80d"}, "metrics.PairwiseDistancesBenchmark.time_pairwise_distances": {"code": "class PairwiseDistancesBenchmark:\n    def time_pairwise_distances(self, *args):\n        pairwise_distances(self.X, **self.pdist_params)\n\n    def setup(self, *params):\n        representation, metric, n_jobs = params\n    \n        if representation == 'sparse' and metric == 'correlation':\n            raise NotImplementedError\n    \n        if Benchmark.data_size == 'large':\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 8000\n            else:\n                n_samples = 24000\n        else:\n            if metric in ('manhattan', 'correlation'):\n                n_samples = 4000\n            else:\n                n_samples = 12000\n    \n        data = _random_dataset(n_samples=n_samples,\n                               representation=representation)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.pdist_params = {'metric': metric,\n                             'n_jobs': n_jobs}", "min_run_count": 2, "name": "metrics.PairwiseDistancesBenchmark.time_pairwise_distances", "number": 0, "param_names": ["representation", "metric", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'cosine'", "'euclidean'", "'manhattan'", "'correlation'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "timeout": 500, "type": "time", "unit": "seconds", "version": "9fed496f3dad2c9dc76f028f417784b342266ee16197672e899e403a5447b57c", "warmup_time": 1}, "model_selection.CrossValidationBenchmark.peakmem_crossval": {"code": "class CrossValidationBenchmark:\n    def peakmem_crossval(self, *args):\n        cross_val_score(self.clf, self.X, self.y, **self.cv_params)\n\n    def setup(self, *params):\n        n_jobs, = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50,\n                                          max_depth=10,\n                                          random_state=0)\n    \n        cv = 16 if Benchmark.data_size == 'large' else 4\n    \n        self.cv_params = {'n_jobs': n_jobs,\n                          'cv': cv}", "name": "model_selection.CrossValidationBenchmark.peakmem_crossval", "param_names": ["n_jobs"], "params": [["1", "4"]], "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "6801caf1f8cd21ed17a0095ee8a6a4f32e18fc9c4fda5efc812cd8c88053146b"}, "model_selection.CrossValidationBenchmark.time_crossval": {"code": "class CrossValidationBenchmark:\n    def time_crossval(self, *args):\n        cross_val_score(self.clf, self.X, self.y, **self.cv_params)\n\n    def setup(self, *params):\n        n_jobs, = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50,\n                                          max_depth=10,\n                                          random_state=0)\n    \n        cv = 16 if Benchmark.data_size == 'large' else 4\n    \n        self.cv_params = {'n_jobs': n_jobs,\n                          'cv': cv}", "min_run_count": 2, "name": "model_selection.CrossValidationBenchmark.time_crossval", "number": 0, "param_names": ["n_jobs"], "params": [["1", "4"]], "rounds": 1, "sample_time": 0.01, "timeout": 20000, "type": "time", "unit": "seconds", "version": "be3520243b65d79e9c474fd2297b14127cf9de93ebc3c36d5cbf473e515a7f51", "warmup_time": 1}, "model_selection.CrossValidationBenchmark.track_crossval": {"code": "class CrossValidationBenchmark:\n    def track_crossval(self, *args):\n        return float(cross_val_score(self.clf, self.X,\n                                     self.y, **self.cv_params).mean())\n\n    def setup(self, *params):\n        n_jobs, = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50,\n                                          max_depth=10,\n                                          random_state=0)\n    \n        cv = 16 if Benchmark.data_size == 'large' else 4\n    \n        self.cv_params = {'n_jobs': n_jobs,\n                          'cv': cv}", "name": "model_selection.CrossValidationBenchmark.track_crossval", "param_names": ["n_jobs"], "params": [["1", "4"]], "timeout": 20000, "type": "track", "unit": "unit", "version": "74d326542acd7965a4ac38cd7dcbf848a4ee175d5aee479001a1e7846287e113"}, "model_selection.GridSearchBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.peakmem_fit", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "d2dd984f5f9ffe61ece803d4ee2f05375513c546c7de765e24ec1edff3359d75"}, "model_selection.GridSearchBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.peakmem_predict", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "0a181b0ce7fbc54bf6b7032db6b39562542ddef6a35255668b9a088799e225c3"}, "model_selection.GridSearchBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "model_selection.GridSearchBenchmark.time_fit", "number": 0, "param_names": ["n_jobs"], "params": [["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "time", "unit": "seconds", "version": "6e8041bfb2a873d368978c028fbe561790c06c5a0d0ec5e6110543525f5cb9a2", "warmup_time": 1}, "model_selection.GridSearchBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "model_selection.GridSearchBenchmark.time_predict", "number": 0, "param_names": ["n_jobs"], "params": [["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "time", "unit": "seconds", "version": "dcdea000aea14892ba793d2354b387d4a23d187fcdc6d32e167d544ba4e2b0cc", "warmup_time": 1}, "model_selection.GridSearchBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.track_test_score", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "track", "unit": "unit", "version": "6469d2e25b08248849a365b43fd7c9f442201399d7a690e1962a95df3b39722f"}, "model_selection.GridSearchBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.track_train_score", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:55", "timeout": 20000, "type": "track", "unit": "unit", "version": "e3c89e4a58c0cae0a5999ef85ae2809732335d78588dd2e02b3005e5535606fb"}, "neighbors.KNeighborsClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.peakmem_fit", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "43360d17ecddfc1659b798464839c3bac0e83d375aa1053cf4cbc45f2107f868"}, "neighbors.KNeighborsClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.peakmem_predict", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "a9b867976f10c5b9de77e884b025c937079c4736d48a0a916aafb215ccd5c6b5"}, "neighbors.KNeighborsClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "neighbors.KNeighborsClassifierBenchmark.time_fit", "number": 0, "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "neighbors:18", "timeout": 500, "type": "time", "unit": "seconds", "version": "b69699ce3d079dbb3cdb110c8538804c4b1121ef6f38f473979b0063bbd0c42b", "warmup_time": 1}, "neighbors.KNeighborsClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "neighbors.KNeighborsClassifierBenchmark.time_predict", "number": 0, "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "neighbors:18", "timeout": 500, "type": "time", "unit": "seconds", "version": "e855c72d2ecca559cf5a5b0281ee724eaffc87fd376347c28ae6d9007b7889a4", "warmup_time": 1}, "neighbors.KNeighborsClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.track_test_score", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "track", "unit": "unit", "version": "7579889d2fe88fa901e741f40636a3145f8df3dc88ddbc26962d150f48a68a80"}, "neighbors.KNeighborsClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.track_train_score", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:18", "timeout": 500, "type": "track", "unit": "unit", "version": "08d43de9f99e9a3f1640453df03be3a7dd66740bc8ad71de8f6931c856f9815f"}, "svm.SVCBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.peakmem_fit", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "d61868e19dbb13fb2fe3bf053eb8b41c8a099a959f559ff9ca2d4e96639488ec"}, "svm.SVCBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.peakmem_predict", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "7bf277d2275581194a28809fe59ba881f789d3251b6934680957c18ec833bed8"}, "svm.SVCBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "svm.SVCBenchmark.time_fit", "number": 0, "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "svm:14", "timeout": 500, "type": "time", "unit": "seconds", "version": "87b16eef694e92177abd53b94cf22434f4d1d2b24472384edbba12f3ffd79e5d", "warmup_time": 1}, "svm.SVCBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "svm.SVCBenchmark.time_predict", "number": 0, "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "svm:14", "timeout": 500, "type": "time", "unit": "seconds", "version": "008eecb5025ad842ac7693131008e28a6fedfb423560d9692b596b7cb69f905a", "warmup_time": 1}, "svm.SVCBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.track_test_score", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "track", "unit": "unit", "version": "9bfdd3bfb929bf4d6c394a4e6b3e766d2887a161011ebeff3a32e20d4f46dc98"}, "svm.SVCBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, 'predict'):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(self, Benchmark.save_dir,\n                                      params, Benchmark.save_estimators)\n        with est_path.open(mode='rb') as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.track_train_score", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "track", "unit": "unit", "version": "e43292f2ef23d0a9c445b7e69128d96e90ea2522bdd8858eae0051bc20d54385"}}, "machines": {"sklearn-benchmark": {"arch": "x86_64", "cpu": "Intel Core Processor (Haswell, no TSX)", "machine": "sklearn-benchmark", "num_cpu": "8", "os": "Linux 4.15.0-20-generic", "ram": "16424684", "version": 1}}, "tags": {"0.1": 395, "0.1-beta": 382, "0.10": 7904, "0.10-branching": 7872, "0.11": 9357, "0.11-beta": 9331, "0.11-branching": 9349, "0.12": 10436, "0.12-branching": 10413, "0.12.1": 10778, "0.13": 12373, "0.13-branching": 12368, "0.13.1": 12748, "0.14": 14698, "0.14.1": 14725, "0.14a1": 14515, "0.15-branching": 17074, "0.15.0": 17279, "0.15.0b1": 16940, "0.15.0b2": 17075, "0.15.1": 17645, "0.15.2": 17934, "0.16-branching": 19198, "0.16.0": 19375, "0.16.1": 19504, "0.16b1": 19199, "0.17": 21113, "0.17-branching": 20502, "0.17.1": 21601, "0.17.1-1": 21602, "0.17b1": 20509, "0.18": 22393, "0.18.1": 22702, "0.18.2": 23197, "0.18rc": 22265, "0.18rc1": 22268, "0.18rc2": 22283, "0.19-branching": 23280, "0.19.0": 23480, "0.19.1": 23768, "0.19.2": 24417, "0.19b1": 23283, "0.19b2": 23307, "0.2": 590, "0.2-beta": 587, "0.20.0": 24809, "0.20.1": 25159, "0.20.2": 25261, "0.20.3": 25563, "0.20.4": 26284, "0.20rc1": 24644, "0.21.0": 25841, "0.21.1": 25874, "0.21.2": 25910, "0.21.3": 26278, "0.21b2": 25766, "0.21rc1": 25758, "0.21rc2": 25767, "0.22": 26953, "0.22.1": 27063, "0.22.2": 27300, "0.22.2.post1": 27325, "0.22rc1": 26820, "0.22rc2": 26881, "0.22rc2.post1": 26890, "0.22rc3": 26944, "0.23.0": 27604, "0.23.0rc1": 27571, "0.23.1": 27674, "0.23.2": 28086, "0.24.0": 28542, "0.24.0rc1": 28502, "0.24.1": 28626, "0.24.2": 29085, "0.3": 745, "0.4": 998, "0.5": 1969, "0.5.rc": 1915, "0.5.rc2": 1917, "0.5.rc3": 1919, "0.6-rc": 2701, "0.6.0": 2711, "0.7": 3151, "0.7-branching": 3102, "0.7.1": 3212, "0.8": 4037, "0.8-branching": 3905, "0.8.1": 4684, "0.9": 6225, "0.9-branching": 6177, "debian/0.10.0-1": 7919, "debian/0.11.0-1": 9369, "debian/0.11.0-2": 9799, "debian/0.12.0-1": 10457, "debian/0.16.1-2": 19920, "debian/0.17.0-1": 21126, "debian/0.17.0-3": 21322, "debian/0.17.0-4": 21323, "debian/0.17.0_b1+git14-g4e6829c-1": 20955, "debian/0.17.0_b1-1": 20952, "debian/0.2+svn625-1": 646, "debian/0.3-1": 755, "debian/0.3-2": 811, "debian/0.3-3": 813, "debian/0.3-4": 826, "debian/0.4-1": 1016, "debian/0.4-2": 1131, "debian/0.4-3": 1288, "debian/0.5-1": 1977, "debian/0.6.0.dfsg-1": 2743, "debian/0.7.1.dfsg-1": 3289, "debian/0.7.1.dfsg-3": 3741, "debian/0.8.0.dfsg-1": 4054, "debian/0.8.1.dfsg-1": 4696, "debian/0.9.0.dfsg-1": 6511, "sprint01": 1207}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}