{"project": "scikit-learn", "project_url": "scikit-learn.org/", "show_commit_url": "https://github.com/scikit-learn/scikit-learn/commit/", "hash_length": 8, "revision_to_hash": {"382": "e6989efd71a2adddd03979d1fe7a2e82e37ea51f", "395": "8ff9fc895bd6032636e3716f02773fdcd9cdd3d3", "587": "0e1faafec9871df73e875a0aadfcb67ec578c0e5", "590": "a40d325cec40da6cbcff8193a4ab4890823dfc76", "646": "ddc6d8f80dcf0a6cdd606efdefb89211a4dc7e9d", "745": "8a4bc2f03733e530591d6641f266a60670a373f1", "755": "8216797c4b1abca9dafd8de9d65472d32450b389", "811": "c7208c1a43335179ccddafc7748c1d7224e904fc", "813": "47890ac823314f1a9e2920dff7575850af56c273", "826": "b573fc0dcbfc2528807b5f0f8c0bc719c25d36f4", "998": "65d06f830ec6604b44d1a0510255868a8f762e3a", "1016": "9072aa593d76262fe445cf492ffac77e853501ea", "1131": "959e267898090e3c68ee118d5048afad124ff61d", "1207": "c83447b72c4f48ceb8249ea394ebf042618b8a2a", "1288": "f13dba15e3d56455c58867685ec554755a346c32", "1915": "d6b4444bbcc54a241cc955a5ceea80be15e7db2b", "1917": "60589710bd64e1fb2ede4d34d7fbb57e83892c86", "1919": "eba9984f735478d47c956ede42bdefd28aa6f9f6", "1969": "0f148e0011fb873bcd70cb3cc01690e7d621f670", "1977": "dc72677a9c13a656cda8be4b23cd897b56109b4b", "2701": "2c3d9e2fce5d2bae27e10657aa3c7ff45c39b190", "2711": "87741a7c65768464eb15f0976ed4bf6312795e7f", "2743": "03a85c19ac2854f2a33f613f87e81fd5f4560f55", "3102": "c07f9574c902b68744434d7b43f7394e0801d64e", "3151": "8a195624128da773c7d584d9352f65d8241cc92d", "3212": "897201083fd584a310cb8a2870704470dc28474a", "3289": "bdf3332f9694f8ecbdcf7ab0391989e24ac13f88", "3741": "5a1e1f48433ba867fb035b9dc31882f8d90f7744", "3905": "af6ab92b3bc0286e401218631859ee50f8be23f7", "4037": "f7c9f24511d9b32add23e75bbf0a2a6c223d932f", "4054": "8b2aaf069306d6b61b49a29d32123e69991c153b", "4684": "cf5c72eb9dc7696b5fac61466605b2860942946e", "4696": "3b48abd5fb0fa4f87c09f6b21d0d1f0e8b7873e4", "6177": "3e3872cde115550b75bb25c47c109b8bfd070eab", "6225": "3f1ea662ee1b1b08cee63cc31e4e3e36ec532208", "6511": "bfd36aa504078ce58f727f7f37e17349ab290e7d", "7872": "4533aa33daa35dd68c6d433b1d3560ff2b65b252", "7904": "34334f5ce6b1f166efda8652310133f9fc36ed04", "7919": "79749fd2939781e201191ef081143d8a575984e7", "9331": "34c2904a95a707c6e6148480a7e2c86a0f7ad86b", "9349": "73fdf6a9c982758be6da71a932ec4a3613eccbbf", "9357": "4ae44b0fe10b3ddf8390cfa8deae4dec45c40666", "9369": "7eb39fa0dc43ce485d3af2857c587811332eb148", "9799": "114822b1e18c9d7f887c58b8a3b2c279bdce6d35", "10413": "4bc8822c846de0d3b70d006ea32235d4375a575b", "10436": "0fede44fb39d691e873d58a4210452aa93c462a5", "10457": "b9ed384195df7b8d7824eac42f7b1bee58ef321c", "10778": "0dd2e39c1f7aec6830e4348fa63a04939252a0a1", "12368": "3e89aa5f42519d7f0230b99948553a8eb33dc1f4", "12373": "86e8b0d2a3533253a7082591f572d73897c02a2c", "12748": "8075887585b0449b6e87ee54c2ca4dbd56960e1e", "14515": "fc0b766ceca487504b040896124a3d809af2975b", "14698": "d13928cc0653f52de55e22118915b0c5bcba13d7", "14725": "34c4908369968dd0f77897ec9dd8c227e7545478", "16940": "bc8666f60f2c8c9ba16b30fbe0b342c3b94213e6", "17074": "68280fb4254b0781a66a1d2689708068799f0bbe", "17075": "b4e8b3ca4366901998c116540902d2687e0a5450", "17279": "518002955b0d6539f8f5e2710b9cefb178cc8ee2", "17645": "d4906939b1ef86657e6617d8fa078a0fbe0c2472", "17934": "2068ff2fd94abe4f14b0334eb4372a64b268f6b4", "19198": "4cc0235ec1ee654ea85cf465d280d33bcb1db20c", "19199": "09dc09a1e9d9088c2cb783c818980f5509d77a11", "19375": "df9f90cfa8795b6d85056f70177fb783d6ecafda", "19504": "bb39b493ef084a4f362d77163c2ca506790c38b6", "19920": "25082e522c90fa9184789f6bc450278b3e18fdda", "20502": "c0c2c737971b52e04b1f6516dfa1bfb05b30f4fd", "20509": "cd12906cabf3576a8c236a4128e959360037dde0", "20952": "918005fd5441650ae4a49b510bcabff69ae898bf", "20955": "b5383488c4b8b97b000585e61ed4e2178fa84d36", "21113": "da4f480a6adf5fed30a42500fe0e5a21c404ac2a", "21126": "82fb053536803f172def9f64e0d62151529173a0", "21322": "2999a2f544cd56575d940d7ab359819b392cccae", "21323": "3c546fd1226a895f68d317d2430daa71fc13e093", "21601": "ea042f1485d5fe45bcf2475c3070cab4e5ac3381", "21602": "51a765acfa4c5d1ec05fc4b406968ad233c75162", "22265": "4d9fab55b9e14e01a7d13344a2612ed802d0c113", "22268": "b687ab371d990373c4a599399172cf31d2f0c350", "22283": "cef2b62701f80ff50a37528b5337dd9a96f0069e", "22393": "38030a00a7f72a3528bd17f2345f34d1344d6d45", "22702": "a5ab948cbc366d705b1f8db8687c7162f51de22d", "23197": "759f4637f9f9471cf4218b9dffc00b464790485b", "23280": "36bc053a69ac5b9ba5a54cb2bd19adb33dcde50e", "23283": "62523372fc6331fc55df73a94d65bfa48c45c193", "23307": "83816c2a95e2ae3c4b3546912de4f4266e0c230f", "23480": "81ba62fe053d56e228ce097cbca91bc5de2e3f82", "23768": "b661a9c81930429cba4a56af291ce2bf8c59f8c9", "24417": "8c439fbe8c340389d7f9d99884180b2e7b21a79f", "24644": "eb6764936c9558553f7a7203a6aaa0ddc6497875", "24809": "f659f5539f9d36ebec4e1d98538919b55299bba4", "25159": "55bf5d93e5674f13a1134d93a11fd0cd11aabcd1", "25261": "7389dbac82d362f296dc2746f10e43ffa1615660", "25563": "7b136e92acf49d46251479b75c88cba632de1937", "25750": "ee986788cbd3256f0c36d2ddae155d8ca8f7be1c", "25758": "be2f62b2bfb40747a2dab20f29a341879b247a3c", "25766": "60eb00c72541b42697fa017fdfc74935299fc455", "25767": "93b19b04d3c81f9824b23e1b910126d51f3cd342", "25841": "a243d96336cb4f50ca3635b3062a273f3dc5183a", "25874": "b7b4d3e2f1a65bcb6d40431d3b61ed1d563c9dab", "25910": "e8602bc04e5c7ab32e6acb887b68172098f7f1e2", "26278": "1495f69242646d239d89a5713982946b8ffcf9d9", "26284": "bddd9257f39f190fec3d72872cff73c2b3cc2734", "26819": "db6c12fc117500a751799a3082d1503b65183920", "26820": "e36317b50d70453622ac6d0324a700816bad21c1", "26881": "d39134bc77d9f9a5a0316e21ee32ac3f9683da3d", "26890": "f1f765f476c3cb3e0a882324f8ed67763d76ed26", "26944": "0a56df6dbbe4f1a56cb11d132e43641d7358dd7e", "26953": "5f3c3f0378f2f30f3c4340bd9bf1e211e96d5c3c", "27063": "e5698bde9a8b719514bf39e6e5d58f90cfe5bc01", "27300": "4b7331eeb746b3facb4d70e1760c58ebe8b47f2e", "27325": "daefc22f832177dcbb690369058e0ca776944188", "27498": "a1261a7e18c19bb3dfc8d739a6512c6f671d9e79", "27571": "22a7d5bc722b0430908f202e3ea40aa2ba1a0361", "27604": "483cd3eaa3c636a57ebb0dc4765531183b274df0", "27674": "fd237278e895b42abe8d8d09105cbb82dc2cbba7", "27937": "91a0e4041e6a7ec3752b394956473503e87a5924", "28086": "0fb307bf39bbdacd6ed713c00724f8f871d60370", "28255": "d2cd2540418d3ff66b324ec18566dbe0b5991b40", "28261": "ab3dc9fdf31f35854b390168ac68fb304951305f", "28269": "2828a889bb96f3507ae0b38721d1e37b9f3e553c", "28272": "8b68ea165cb11625254d17c73603c4724d0b6d21", "28277": "74b632a1aa880a9c7f855599d16603626edf97fa", "28278": "28d84693b3855e9a1bf02b61392fb9f31055e897", "28284": "54ce4222694819ad52d544ce5cba5da274c34ab7", "28288": "bc39e62e02b9de82c2a266bb47beac4687843b51", "28291": "df61e9ed98b0777cc0962be6e2d161f4c30110fd", "28296": "13bccedeb02fa650a247a8ab6420bf9d44df3424", "28302": "7ed972193590c2a11839e15db87fa4818089de1a", "28306": "21121f50997dba43fffbfecb2f672431cf708363", "28308": "3bb138f87964dde5f25846f4380afba012cf26bc", "28311": "aa4a10dbfaee9fd52af06f0f0c8e8ae77f243ef6", "28314": "f35457f1fc3282d9efa21a6dc0bfe5a5e8a2f40f", "28320": "58451568d3b44ba632d708add02f9c30f356570a", "28326": "f2635e27894e6fc8c15b13284d3b277dfde65d71", "28333": "3b334c5b257465c5253b5a714eda7b34bc046b45", "28339": "193670c2a17c6a76f852e21cfafb954d195c9d29", "28340": "e6555decf8a72958d26d499deb17aabca41a562a", "28345": "fdb9233f72caec3d3f9720e073b2efdc141847ff", "28347": "1f217f33a25e6033bd0160ee22695186e12e7744", "28357": "cd673475bde70e87255ccd9b6f35687ce59b4b67", "28360": "6ca9eab67e1054a1f9508dfa286e0542c8bab5e3", "28361": "5654da026b7f1186b3a840d1cb140b6598b0af61", "28365": "5d5329c473791c90ebc58b4a18a923d1e6c216b9", "28367": "160debe468890e1dd90b610d5505eb118481cbcf", "28371": "d933c20befea779f9bfd35b4d85adaed9c30d684", "28373": "28f61efad3c4ce6536176978aef0fc857a35ff7b", "28376": "f1111be2fa9899a610843c36d203b0fab02f16c3", "28377": "547feabbb02de7da88bbc692e7b81419e373a0cb", "28381": "dccaf4c867c5ba254b1bd576101d30df40c00760", "28390": "aad222316754a072a893c5e735d4f3f6bd792725", "28392": "8471c8389d794309b0b62a353e3af903acd48223", "28396": "38a50f4c7b429dffeb94ed5abb428da06d0ba859", "28397": "fb67c7bb00f4d68ecbc65e8c46af5372442274cd", "28404": "a2728ac8d4dbc241a997899da61cb0fbf4eec96c", "28413": "4d7e61159db3fb59c474674b3d9f9c656d310e49", "28416": "51acc9dda812efca3c28d97ddc380c421c4949db", "28417": "f0e9d298be351eda7eb7302d6e673b097ae79831", "28418": "b5d63e34746ec273c1cbc5992a0477198a22f8be", "28426": "7db70d5b7988e069088f9956a28f1039e799b709", "28428": "b3806f77895d1146e83fbfdd60c6be43d4a7c144", "28429": "f77fb7265ff9425efb355890107d31012b2c8f33", "28435": "8479a74af207d857da4188b75375ce9d24c7ef90", "28439": "f650d9420bc75e70369fd8c5c96f965b58c0b1d0", "28443": "5a8bbf0195236b2e85217f90c363e5e7f975f157", "28449": "84bd4e29680a9a95ca01143a6ba79a42bc6887ef", "28450": "ffcb869d4b4fc2609b123ac7d089d00791c30f5f", "28452": "b4453f126f34447967f52996039d11b0d2fa0090", "28454": "a85430acdd49b7a63a4de110ee437d092d460d70", "28460": "2f09bbb7eb2fffdffcca3667b8fc38990d3b0893", "28462": "5a09d87da357660f8d16abc2eb424c67db5710c5", "28468": "5fb02bb7bfed1a5edbe12ce942bb77cacde8180b", "28469": "35320845c24ee58a21a99a2df044084e0e65f3a4", "28474": "63d2bbf1ef187d026641514cf511648cedf94701", "28476": "9d394c2daab6df104cef115ebd69f802cc327347", "28481": "eaa45c86f74c41828a92db4d4da2eee643cbda02", "28485": "da562b4fa58bdce4a7f3470f733f33d728747a66", "28487": "fa5f1d5fe3e9a354b32a27a0a24cecef7babebb5", "28495": "59f41f03755fa28495f514a795e19154c0273e35", "28497": "255718b4ad9a3490bc99c992d467f85737bd1291", "28499": "e21319fee78d75e47cacb747aa40b5621f5b04cd", "28501": "2c1719e68e243c71c32c98958cf270a49e7a521f", "28502": "7cb6b8fde70bd12501e85be8102c46b8ca48405f", "28505": "4773f3e39d788e734378f32064cf2e5629fbc7aa", "28506": "c9677d6a7d42aa7162a4c448284b8db1cabde0b0", "28507": "8ebb614a8dc09c7baccb45c6a2cd7d087d8e2ed6", "28510": "0937b4ab48136eb161ead4abd4806d0708b1bb4c", "28516": "95128d3e6d9231703517c732dc73ca8c18adb9d0", "28520": "d304331b450344e4660550b15d8174b15fb616c7", "28524": "be4f8a509f1382a9bbd24194bcfd19c6563fcf31", "28527": "2218ec46227c92301ac6837c4a8ae9b8dc5d3960", "28529": "54375d24a423d77fc5fac1071643a588fc98e818", "28532": "6af03a525c929312f26986f68d3866c217a6838b", "28536": "a92ec1b7582b14fc20e57ffe0c9aa2a00f637766", "28541": "45a817933ef51a24f0c5863c1026b4fe664b26fa", "28547": "6b4f82433dc2f219dbff7fe8fa42c10b72379be6", "28550": "5946f8bfed039540c7527a06f2e6e9f1fb2335c3", "28551": "def0e68085a4339490325dcbfc79143f21ca001e", "28554": "e325bf760f55fb1095a66f1223af2cd396685b2f", "28557": "dfc5e16066b3a3bbf34238cc0f67639d0965f1a8", "28561": "cbfe0ede80beca86750ab8113f17c18c8c8042ce", "28565": "266a11b2e17cf86effefe7b498b61ca31217ad31", "28566": "1e46db669318fe20458d7cf135f6107e19e90970", "28567": "34de1b9b2122783601b245450a1885d18558ac81", "28572": "aa1918cecff1161c36fcf06fa0fe4d1c69ece701", "28575": "be4c1d1fee6ee3ec40935283f9e1ab22ebce27cf", "28580": "0e546ebe5b5a97283ce03f915a83f0d2651394e0", "28582": "9b2a3e8ba50804e5cd1e4302097e86aebd2e8464", "28584": "5a63f903ff1d45084c4fd41f241bf5dfdd067680", "28585": "1fca00b0b46e89956f76e118581a4176888344ab", "28588": "28efdcc5a646fbb8da2456a0f4b8ce7968432242", "28625": "c6512929fbee7232949c0f18cfb28cf3b5959df9", "28629": "e4ae68f09a258d9578f640ff74ca6e209ec37dba", "28631": "9183486463c1df3b5b3c7e2357e17533bdd36573", "28633": "364b1e3e13a48446f86e4682bbf09ba4f010903d", "28639": "8c6a045e46abe94e43a971d4f8042728addfd6a7", "28644": "0f0eb522903431b07f6e267b8b0d42ef24659cbf", "28646": "6f32544c51b43d122dfbed8feff5cd2887bcac80", "28653": "e449f9f1be7dcb937ace1327a4b0c6728afafafa", "28659": "0aee596bb32136df8c68371d696770251c7d14a0", "28663": "c86076fbecaac1f6f5f068a5332871f5dd0f8451", "28667": "ff2e52da0c09e8cb2d9a1b62bd4c3ea481187308", "28670": "b94332434d0117e3d86407560a206d1c7bee1c81", "28673": "38e6022e24e1a3c91f932fec87302ffc0610651b", "28674": "88be2abb7b7f7450dc569e0065e672a0676e4130", "28687": "94b81ab2e7f9b0170b2d6ba6d84c1cc913367d8b", "28688": "50d3aaad36fa83f5d43e8177838726dd08f0526b", "28695": "74a37de119d2c7c9ea1cce673c2ee207541a55d2", "28696": "819c43cc7a1d7efab855e982a91e15be7aec7db1", "28697": "23d8761615d0417eef5f52cc796518e44d41ca2a", "28702": "d6bd7bee8799ea41c456c36a8ccf7780105615e8", "28706": "94337993ef1a29146c67d7e4a51e3053a79e92b7", "28712": "86bc6c9858dd1660f5762003a45733f50fc7a748", "28715": "5403e9fdaee6d4982c887ce2ae9a62ccd3955fbb", "28720": "4aff3857bceb1e42af5ff304140bd4d5b7e74e67", "28727": "6959532d4e43f4434993c027c7b2df09ade942ad", "28734": "dac560551c5767d9a8608f86e3f253e706026189", "28737": "b251f3f818e8d3cdb7ef843006d19da87755d444", "28740": "4d60a815d84531ba91bf097e9c814460113a7b72", "28748": "e9c6fcaa17b983858400465fd39a2616c980c3db", "28751": "b5e55f79fdfcb0f41f0cfb279e54a123822bca43", "28753": "70c6ac9d04c396faaf604c2fd1d3945f25e4d6d4", "28761": "26c5530e792c1319ddd3335e23d1f36cf90f6c3d", "28764": "e23dd851476ef54c2153d6178500a3e2345f95b4", "28767": "638b7689bbbfae4bcc4592c6f8a43ce86b571f0b", "28775": "94abe05b4b96de2ca30d998fb9adb2fbd3eb1bde", "28779": "15c2c72e27c6ea18566f4e786506c7a3aef8a5de", "28782": "72db93cc40884f42e05e4290d6ab63713d0075c9", "28786": "28ee486b44f8e7e6440f3439e7315ba1e6d35e43", "28789": "1045d16ec13b1cab7878e7555538573d1884aad3", "28790": "42e90e9ba28fb37c2c9bd3e8aed1ac2387f1d5d5", "28791": "f2773e840a0fcc9dd673cdd0da82dc43299a713b", "28792": "ae3d955c90d03479d4b6a8a3b359fba10826dc2a", "28794": "4beb0c27fc0439c12dad244fe4063e96f8983a52", "28797": "6f180d79f58b42a3fa06055c489b1edf857399ff", "28801": "15fd026963be233d37752f322b5dd484c58e09a8", "28802": "f4e692c0876425ef6afb6f514b54696f3e071c35", "28804": "0c74b8b7d5cdb60dc3a3240cdb36af40b9f40288", "28808": "302106bcac4476ecdd76b8c03fddb454edbcad96", "28811": "b7b510f9dbc87500e79301873852c6247c440a3e", "28817": "04f84c6d082864c208682d27256ff74b7b488734", "28820": "0d7d46f3bef0a2f943ee321f0f979ced165e0477", "28827": "266400e60ddc0bdba1f0de02ed49f45893e5647c", "28829": "3e45aeef901871b84ce59709e62f3d2245463cd8", "28834": "81102146e35c81d7aab16d448f1c2b66d8a67ed9", "28840": "114616d9f6ce9eba7c1aacd3d4a254f868010e25", "28841": "4dfdfb4e1bb3719628753a4ece995a1b2fa5312a", "28851": "f0576399d9cfb41c1f3cd4a0a2332578b1c0b573", "28853": "f47926999d35686ff2190c3940c82d7cc7f3e691", "28855": "c957eb37b5988e6e2a4692c1356e8689294404c5", "28859": "9cfacf1540a991461b91617c779c69753a1ee4c0", "28861": "36c635b77f9744b627248f96f15f3e73e97d3571", "28867": "132627e28b5be807b1e4b7d58bedf42b529d7800", "28878": "3ff1267a7b74259dd0f0fdaf7da88b02e727e7c1", "28879": "b1d686d07559fb83040cb085b752d86ebbb9b3ba", "28883": "c09c654ed4d5833d73f557381f3d10f3d062e5d7", "28890": "7fa2e6e2734b590d96e62d5932c648a9c1002f34", "28893": "138da7ea911274f34d28849337c2768d7e3a7a96", "28895": "2c5ea4e6b3add57588fb35293b7dd25506c5fe06", "28898": "e1f879e8eed85c5018d888c9f87f168bc44085e1", "28905": "0df9efe2c1407f3fb887c22056452c791fd83dc9", "28914": "004b44d007408aa2db1fdaf4428990d0d7b7f85a", "28917": "a67b284f90299989c4cc03f848dc9cc1be57c623", "28920": "c88c89cffd87c34299ebb8db6192c973823bd827", "28922": "2641baf16d9de5191316745ec46120cc8b57a666", "28928": "e4bb9fa86b0df873ad750b6d59090843d9d23d50", "28936": "a45c0c99a38cffca6724cb8fd38b12edd4fb6b35", "29084": "15a949460dbf19e5e196b8ef48f9712b72a3b3c3", "29085": "a9cc0ed86fca1480acbd8aaf211f062ee2abd5b7", "29086": "9c3b402f0082cfc17da3ab9430a203ecc2ac4dfc", "29088": "4023a0f94bde429456f45b983c84c5f35475480f", "29090": "a9ce392f3a58da5caf5ac9bd287205e220082fc5", "29092": "0eb9ad73c53c8f3cc0ea03d33312035853bee29b", "29093": "de1262c35e2aa4ee062d050281ee576ce9e35c94", "29097": "2bd3a4db529d707a9862d69cc1ddbcbe7a6054b8", "29106": "847fc6a27431d96eaef926773608168e8edb9e12", "29108": "48ab1bf71aea9b7036108179e00e0b2e1c3fcf7e", "29109": "f6e6ad2d9e9172c55c778392b27b69c6af87bd98", "29110": "5073d692f04dea88d595252a6cc0382509b6947d", "29111": "d73822f84f2832dcc25f0ff58769f60871a78025", "29113": "053d2d1af477d9dc17e69162b9f2298c0fda5905", "29115": "ca6caa28ab92cbf75a3cc2a411d2a225abd9a4ce", "29119": "1ac047d29a43bd1556d5c90e40376340a08bc3a6", "29121": "c67518350f91072f9d37ed09c5ef7edf555b6cf6", "29123": "36a4dcafedbcbb112e1d96fd04e73ba922523bae", "29125": "aa898de885ed4861a03e4f79b28f92f70914643d", "29126": "5b7136f04068e7dcdf5ae8ec4aa729107ee905c0", "29128": "c1cc67dd06d31a9b110377afe0c94b0cd50848d5", "29131": "7c873713df056a9554dd545b0d5f0be93630219b", "29138": "c9d223ccc58e2569b8e67f1d0217dd57a93ec07f", "29142": "deda6e2a5a01ad22096862bded5f66e9578cc39e", "29146": "7bb3e22b3c454a59619a56c314be04b4b303e09a", "29156": "6850c04186b88e88e9c8cd6eb673721af806e3da", "29157": "5d25ce13ae0fa8f1f9e02d046d1820b6dcfd6155", "29164": "1038024a438e2bc76e7e48edde7b7ca732dc506b", "29180": "1cd282d600088d2547d827af72a99e036106417a", "29185": "038c5cd04558e572b6a4dea7383a515ff10090e5", "29189": "9a13bdfaf1a47188d2e1262f0308f317e6662e8d", "29190": "b5e5db4a43e9f79d877a0d88ba94392925981b31", "29203": "0eeebb1e3d59f739f6eb9319ceb254a8486493d5", "29215": "dc2b5875d0465e30fe9a8181a0e07d85d15e66f8", "29225": "0ad2b5b0a9fdc010ff92dd536b102e865ac3c512", "29227": "617ff6ef72f28b7964f2b7fbedaeff7b24d8c2f9", "29228": "bb6117b228e2940cada2627dce86b49d0662220c", "29229": "c3a3b1e602d819e0b2a7b90a344580902be7ce0e", "29231": "572c2cb1c8ebc5ccf5b16573b7199f67912ff87e", "29233": "bd966fb7e43691918669db4533488d7596c1cd69", "29235": "36cc933f41d5eba5df154db57d2597d5bf421024", "29240": "7b715111bff01e836fcd3413851381c6a1057ca4", "29245": "1e2c899aa94526c9e0e916f1fe2463ecd30a35f7", "29246": "509b9ffbca2f73e2724cf073ac564238fae60b4b", "29258": "2a67d88258264eb2b6dfad221be8f8d61684dcba", "29262": "3a57efe45ef7ad3b32f3c3e2813f65316391b668", "29279": "daae053f7e9afc1dac24ce9ecce87f1356b96b03", "29286": "bf7a60a6a217c85620844b083c3935235b3aa177", "29293": "0d343bb2d296ece7205f9e230d98e3ad68ac4472", "29294": "e4ef854d031854932b7165d55bfd04a400af6b85", "29295": "18eef9adf9a0f8995ea8aee0bc4a94afc7aa5698", "29296": "c871c062f1bfb10bcd2cf39c25d233fb614eeff4", "29313": "5a879f4a024d499c74da65f0343b535be4aa096e", "29318": "f2a6e109f7be6f0d554e44cb4cb48b41081dc259", "29319": "d66b42708a5912039740cd08f747229433e579b5", "29322": "f72f1df4b03f63a027e738f644958e062f294503", "29325": "5c499942e0ade18fc1abb9669bd04462256bee73", "29327": "ed3642014be412b0bda13d1ec756baeabb0dcbfe", "29328": "1bd007fe0d5758d48829ea339f06206261fb2477", "29340": "85b0b54285471fd3af5f27ac4d25a6508263a79a", "29344": "cd8201b7fbdf6876719b44ec0abac85a6da583d2", "29349": "f081f5829182529eb1ab666f79c9b917b0b07f09", "29364": "ded59b5713bcbfcaa27d7d9d1de704c96817870c", "29371": "cf286be4f3f5bb9b604efd068aaa87dc303bb4ac", "29376": "57daa2de792121a6a22556f978234192b778e308", "29381": "238451d55ed57c3d16bc42f6a74f5f0126a7c700", "29383": "b41cb296ff137f28c3d100298b507ccb9e63a3bb", "29387": "2844f592be6eba36d952a4a1ad68cc41e2845c27", "29401": "df20e8156fdc06a89ba85952b8b5a32b47ee9004", "29404": "01a28e962ad203b552bd968e5a3564d4b7e2155c", "29409": "4797222cc4547451df8ecdadf2ec29488703b593", "29414": "daec880bff4217f1dd05484ebfcd912377652873", "29415": "86476347b362c8f2f0b6bd5cc9dfcfcec979f07d", "29420": "6b2d5a973a0b35453bb163fda72930dc4791945e", "29421": "81165cabad383db2ff7fd856e467041eea9b55dc", "29425": "cdc486a91affd19b603e8090b46eb5ca262f3569", "29429": "f812e2a27619650463cb12d765f1b443b47c0828", "29435": "416eef462df1a9bbf8e99b91dac58324f8a3f498", "29443": "4b0d291fb30d057980a9bf64331c398f7c425fed", "29446": "5088a402253a275249dbd52fef97d8e58628d28a", "29453": "4b8cd880397f279200b8faf9c75df13801cb45b7", "29454": "73174161931ac283499aaae2e45ec4605c895ddc", "29455": "21eb4686c5a53401b10e815d2f08ef8f090283e1", "29457": "8cf87a30bbd5cbd6444c6f3ed380a3d2b5f67461", "29458": "e648c4cb919151161202130b2e4aea6413329900", "29469": "d6735f4851d828984a0517de954b9b88c74919fe", "29541": "fac31e727947ad53f2ed107f58a10b56b165cee7", "29548": "f46190846c5d8c0bd898d1447a2a07fc50fcee2a", "29550": "9061ff9e58425789338f68563df1bcfd386d93fc", "29551": "cb7271339e56631fe47a22e259c98716f14f6894", "29572": "c0e5d1bc746069e6087d499dffc707d94df09237", "29586": "c21491f05e9ac58ef4b4a7f0c3ec0e9c06b4a05a", "29591": "89d66b39a0949c01beee5eb9739e192b8bcac7bd", "29598": "40e1f895b172b9941fdcdefffd5a2aa8556ed227", "29609": "047cc2ec0cf71cd7233a7163a847b197e3a4acf6", "29611": "517b38ad30f36c6fe9eaca2c4a496ac1c63b3f50", "29621": "597df0ad17fa75d7a6832f71e7859fcb1925e29c", "29636": "e00e000c9a96b1f2173f352769d8c590ce6e0113", "29638": "f309ffb2a6c7638f25eda75873578c948a2bdecc", "29644": "5f6abe6f7d64fb5e1fa7dccc0aaf4ec2e217cdc4", "29648": "8fc351656a44789893bd8b092ea12fbbf5b803ca", "29652": "f71c0313142c4e5f2f35a0021c36075cf8dba611", "29656": "efa7f7c8753aa84b4b001d699aa6c70a2929813d", "29657": "6c566da8c99b4908a549aeb659cd4b1124bc2448", "29662": "6c068e2c75b551c72d3f551e68d7c5a76b6fd7a1", "29665": "47f888239c507358fc7bab7f832101db648b9461", "29667": "0d1e63366c6e361ba89b8588ccc26b01c47a5563", "29733": "9b033758ec681e8fd7433a8bb35d9777acd4f8ba", "29735": "2eabb45d3588bd0bb3422e1b3c2c6189268b3b1e", "29742": "f33fb0af65380e3360cfc9dd7f291ab59e2ef63b", "29750": "2e3c32dcc1e99ad753dff4a9aa26657073883158", "29753": "9cb4e761f530e7a0708059b1312921753d056cbe", "29757": "6d5774f6895aa84a8ec74762bcb29fc7e5173d41", "29761": "e7fb5b8c8dd2cd4d7ccd6f9f9ad6c1d206c43a33", "29765": "4b8888bf864322af1a1ae664d8d39c37b928ac6f", "29766": "d152b1e6e2a02e5bf725b41ecd63884d7d957cee", "29768": "23afd5d95c18915c55070cecaecf9f3030ae9bbb", "29776": "d3429c138a1eab162f3627e14c6ac26f49d59a16", "29783": "8ad7c3f02daae525ee83231fbd33fb65e8e05288", "29788": "8b18d4cbfc3a10ce85decec292d30470c69f40d7", "29789": "b2ee0f4ed1265a2147a6c470373de2990074fa23", "29790": "2f2364de6f6b61a24cefb8a18369f0811f721886", "29795": "682bd050be056e2104b4f9c2df4931bb642e7946", "29798": "57658ba4ba1a8bb00e8bcfa17cba028588ecf47f", "29805": "5f6e17c084c36e9eaee55a7e05f4b2f43be21a25", "29806": "47a49c51d14b7b648be6a4918c1441cb29c96a9e", "29807": "034ee98eae76f2fc5d9ab3b6e52740728821465d", "29808": "2ec028d2e8c34e332c851311e8cf330128081a1c", "29813": "a343963d961225be25468ca64b54896dcba48e87", "29815": "958ccc5bb1d43594eafe825e387e3e9876ac8893", "29828": "9b210ae8ffdc40e210f30f24656779ac690b899a", "29839": "e34b64c7ac57c9e6bfee3e26f27d6d74a9bd913a", "29844": "d4d5f8c7e02cfaced76757fbf38e21c5b28b67b0", "29858": "4c9bf8bbae7cd10baa754ba2bd5631329180fe09", "29865": "ec1248ae8af8e5fe53655f0269d5f4e178c21b70", "29997": "0d378913be6d7e485b792ea36e9268be31ed52d0", "29999": "8955057049c5c8cc5a7d8380e236f6a5efcf1c05", "30002": "f7ecaee36fbcf1847943e122504a4ab7c585bd90", "30010": "d4129527d3e86e34e898885ee8640e2c65900f47", "30013": "bd871537415a80b0505daabeaa8bfe4dd5f30e6d", "30023": "01551ad8db01230c1bb7ae94803f48e337f4db88", "30028": "d5e045fd600bf7f3edd984fe7f8599124a67f7f6", "30035": "8cfbc38ab8864b68f9a504f96857bb2e527c9bbb", "30046": "f8728dfc07af5bb47d97459b78c6729d76f076de", "30053": "9b605b498c6b1ac6b2713432d75d14854a2481ae", "30066": "74bf394b872d9ed9a91a949f04dbcf2239c558e7", "30068": "48e83df4509bb2ae1c1d74570a9efed7b61bdede", "30070": "8aa0ac006ce87cf8a7bf12c40380b14af6ae2a10", "30074": "f2231993675134ca7d01b1b8ebfd6d082372272e", "30076": "d63405f1bb6e4e6f56f59cb947a51ffd48cba895", "30077": "793e90b344aeee90432b47515410c5666097f0e6", "30078": "1b9de7b8b6a1a535b80505db1039ad19b3cc3738", "30085": "016df3326c48e0a78f9efb5871473bff4a09f0e3", "30086": "2368132b70559de2e890d7f16ec10f6247c9d5a2", "30096": "6077d52b706d118c0d9fb1e69c254bc67e15b078", "30104": "7bfa9ccd7c4a6d73bb2b0a99baf6f9515e681951", "30106": "00d7e59d1e4555f68c4e2bd005fa30048c2e3be5", "30112": "432ae47beeaf611547aafb69131834f151fe1136", "30116": "6cdffd860c49d30d3b9fa72c5fc1174e8eeaa35e", "30118": "248f6cf3156f6a48333b4074aac4c12e2c15155c", "30123": "a278f2a2ce49bdd55ccb73bb67e35b9c2ada12e7", "30128": "73d0b4f2d1aad5884738eeaac1aab2c3135fc471", "30135": "f8f77b4acca401904f6e7332bea55067f9d1e797", "30145": "bacc91cf1d4531bcc91aa60893fdf7df319485ec", "30155": "35af6dc808c8d317eb7017d1b16e271c9c8bba77", "30156": "b1a5d3c40ce0664978e41305cfd1e616a8d3dfd2", "30157": "832513a7fb6570c41f3c8bf4bf7cbaf110da300e", "30165": "7c7666c9b9f894e3220f52dfc98d95d658e042b0", "30174": "80ebe21ec280892df98a02d8fdd61cbf3988ccd6", "30179": "3e0f49b62339941722d0dfbcb90f5af0ad1b2e6c", "30185": "3f8868072c1eb7b37ade0a131db37303817ab5c4", "30189": "4035b63f7ff9437e389b720db45f73ef66566ce9", "30190": "b1202af3b379e698539a2719f2b1e28706ce5388", "30198": "5f3d1e57a91e7c89fe3485971188f1ecd335f2c1", "30202": "02b41de8fca096d92aea6a5336fce372b842c5c7", "30203": "77fbdd1c46c2931fb06b373786efd03da90d3e78", "30208": "63a1a31a17f9bd9cdf617b2cf04bfaf2f32f0a17", "30212": "01109213520eccbb9d5a51ed2930e7763c3386c4", "30213": "056f993b411c1fa5cf6a2ced8e51de03617b25b4", "30215": "39782b71b03d180bb2fe2ac321b6bab87a43746a", "30218": "dce9782a0d174d317c89ad52124348fa3bfb4e47", "30225": "845b1fac9e8bcfc146e7b38119ce6c500e00a10b", "30227": "f21f1d7539134fabc93e57309dd3a4717d00c7f3", "30233": "b84d67751753cd7ee81b3ede8d3d16951ddc4cef", "30235": "cece90e57c2b64e56367ddc1bad7edacd4f29e26", "30238": "2fc9187879424556726d9345a6656884fa9fbc20", "30244": "e5cc0b80714223c709d48b832e32fa73bae323a4", "30248": "3e460e8b7e4c6d9eb2041d793a339dddc000b3f3", "30254": "304a14783ffa4eaad738aede0e12a76ae44df076", "30259": "78a941aa73756595baff805fd390a0590262ac97", "30260": "c72ace8cd652309963ecdd6c01e33fa3c58c9161", "30500": "7e1e6d09bcc2eaeba98f7e737aac2ac782f0e5f1", "30501": "9aff4def9890819556e3d32c8ca6b2f27b528c22", "30502": "5dfa5d979a3acb87ba028d0e9e72e3e73bf1657f", "30506": "b242b9dd200cbb3f60247e523adae43a303d8122", "30507": "ed865d7a3363a92846d7955a9bdedae2ad29542e", "30510": "42a34e81a2efd64ddd7b40b433765e7c361cb51e", "30515": "585f4f11bca4c5a4cd2949ebd4ba9aecb9f3dc31", "30519": "5d86281723891c3dda755509f67a524da94ea07a", "30520": "1c24595c74e0bea246737b19f8fdfc8a1ffa2282", "30524": "26e2c38a961a27a9e53ce7814bf27f840510b237", "30525": "49588ff1e677d3d6fddf8798603a06f06fdb6e61", "30529": "ff09c8a579b116500deade618f93c4dc0d5750bd", "30533": "4e974e0d5e0b9e4aeaf83ab5b2f6381c5e122c6f", "30538": "7f61186cbcbc43cd6ccd717abd097f638b786984", "30542": "8d6217107f02d6f52d2f8c8908958fe82778c7cc", "30543": "9daed7f8970c25afaa54f671815afd75605acf26", "30544": "1d1aadd0711b87d2a11c80aad15df6f8cf156712", "30545": "0c65bbfe8ce816a181780d2a249c94dd653e115a", "30550": "ab08e4dba5f1f87b8c3395f32469a6ddb5e34f89", "30552": "9816b35d05e139f1fcc1a5541a1398205280d75a", "30556": "330881a21ca48c543cc8a67aa0d4e4c1dc1001ab", "30561": "08e02167843d857c0fb205479ae32183a887bac6", "30564": "6145cae3d1cefaeffcb49b3080233022bcd1368d", "30565": "cdf0d69c9c0cd2ce400dd79176ed4457a7730d67", "30577": "203caeae4c90331fdd7e087ee27b54a8541bfe03", "30581": "1e4ac040eef6bc8c43c77122bbfdd5d83cb8365a", "30586": "26e1930abf5ad637e44573a152dadbd45fb5db0b", "30593": "755d10a7fcfc44656bbed8d7f00f9e06e505732a", "30615": "254ea8c453cd2100ade07644648f1f00392611a6", "30621": "46d914349dd4027bdb1a69eed4d73694d0b37fad", "30622": "0dfaaadfe2d0e0b4fd9d2ba22a75b7b1b1903049", "30629": "b0067e0e7e0ae095592bc3a9a8cb7ba9e200c1be", "30635": "9f96d42e3966ec0ac778132bf1192ba36f413006", "30639": "581a66316af6b57e6d455b5517c543932f857f0b", "30640": "9f85c9d44965b764f40169ef2917e5f7a798684f", "30643": "fc05d2b1d9e815aabc9f1436a8dabd281d08b0e1", "30646": "77bc7f921c9039f917456d81b0a9db9926b987ab", "30647": "6440856fbb0e1c0a048316befbf6df4e0a5765c1", "30650": "b80138fccb025ec1f8944e1b17d08b5fc2e9d1cb", "30657": "34f4465466028ccb3f7c42d71d97f7158281d6ff", "30665": "bdb7db524a5cb584d975b3bb1823494bcd5eb92f", "30670": "6c09bab585acc708b099acf383fefe6ffe50ca89", "30675": "0cb06ea33ead6bc191e6721942606a6b17ecc01a", "30679": "f9d046766f590af3c181cb2d994ab1ea125d1216", "30694": "3786daf7dc5c301478d489b0756f90d0ac5d010f", "30704": "abbee570f31a91243c22b1892e42056bb915c056", "30708": "e11c4d21a4579f0d49f414a4b76e386f80f0f074", "30718": "111c78214cb92d8a21c95734c6dd0e76d5398db2", "30723": "26d218cfeb80908a52bbfc302dc5f43cef4b5181", "30729": "998e8f2068c7d9f43a30d997b63e4875688d0b1a", "30730": "5c7dac0131eb2318ccd4afad1e2e646e7b83b5ff", "30734": "691972a7cf04e7a8918b907556b4e9904f82bd0c", "30739": "e0ebc7839153da72e091f385ee4e6d4df51f96ef", "30744": "a1a55886a0f615b4e87659af489369a9e66e40bc", "30748": "70eebb992e8a799cbc3d7f1fbfddd104c0908c66", "30750": "34d39c7da61499c7a0e5a57dbb8b02e31a914ac0", "30754": "7a2a0f74ca7b9e452c94ee6de3146ef879dfe41c", "30761": "9ced5ec0b123bbe47179cffff02844ba659a752e", "30762": "c83c6fc83d504b08bd6aab4f12c45d10cf0e9ffa", "30777": "b19c748adb30d8ac1af94dc296dcd424d4631ccf", "30782": "578e3eb532d8ab5396d5579ff06e46604818e750", "30785": "269bdb94898b9944b10de2db6b17fffe7b69a432", "30787": "742d39ca38f713027091324c4555f9b4e1b9da05", "30794": "7d9f1cae7f49ff6bca4e474a4c9e8f4e7b88a357", "30804": "692225dd2cb5058bc006716270c1d48c59172f95", "30812": "d6984db4f2c8ff8c0b29413b40d53903f2123ce7", "30818": "5afd5e160bb731a0445c960fd94740080a44ebd7", "30822": "ee1b6d217f0566115dec706c6256fd81c4087833", "30839": "f6d37b85d551051ab26e04135db5e6db623dd955", "30850": "bbdb2eff9b877c0ae00ed9854099b92119504f62", "30862": "fb4dbfd837483ac3daf06dfc28871bfcfb65c4ab", "30869": "751c5cd05ff545c20ad0b09ac491c07f31e4cd56", "30873": "142e388fa004e3367fdfc0be4a194be0d0c61c8c", "30891": "0b2f4ead15a8b069222c4bd538499c9c739a8f96", "30906": "99262c06c02375ce9579638d0f37ee1ce61807c8", "30909": "7116165f493998cde7989a29458f36bdfb0a9ab5", "30910": "ee5a1b69d1dfa99635a10f0a5b54ec263cedf866", "30919": "2a4b40a0a46b1e6b1271a89fdb466d1c7dfae6ea", "30933": "26eedbd1f453435b7d8f62d151ba23c22a567d88", "30936": "e5736afb316038c43301d2c53ce39f9a89b64495", "30944": "f89a40bd92004368dee38ea76a1b9eaddaff4d7a", "30951": "cb547ae5d1484d6332ea7891ec7d7ac742342741", "30955": "5b901fe5734d1f3900bd8f13534718b007012c4a", "30961": "2c5058e0d6cc4f5c627d2ee256f4735fd5ba4a39", "30965": "d14fd82cf423c21ab6d01f7d0430083f9d7026be", "30976": "fab022e2edf98d745f2ceaf3048e0ca6bc3b86f1", "30983": "86c62cff7121b218f7bd7007bd6880e206561019", "30987": "7811a3a4789f5a252e99708e7bd45445f78839e4", "30996": "59428da95751fa92d46687850932f8f6ab1b4f3d", "30997": "b4da3b406379b241bf5e81d0f60bbcddd424625b", "31003": "dded6761c53a433a8f72b40aef33bf7c2f76e425", "31006": "9858fdd9a34a630499cf34c0b5c4900d6f81d55b", "31018": "41b8f84f1f1eb5930c0ec60598ca1748005a1f75", "31028": "adb47e7c142ce6d699cc5927925d448cb2c1ab91", "31040": "df692c03c1a6003878c6fc4d2f9f222d304dcee3", "31048": "bd9336db0c23b4bb8725cbea34fc9c43cdec70b2", "31049": "aeeac1c1d634dc80abc93fb30b3fe48e1d709b64", "31050": "e275d9df3da36352605f4e68b14593bf9f435c9b", "31129": "c987b5ca84610bf5251ea8fa33b48c5826942a0d", "31193": "16625450b58f555dc3955d223f0c3b64a5686984", "31309": "80598905e517759b4696c74ecc35c6e2eb508cff", "31946": "6cb2c52375a812ff509c00f4eed1da232e7a8932", "32111": "b4f51fd1569a0b90d56061f678f2f4fa7b04bf5e", "32113": "5436818d8bfc7e6499c07f4225aba377899a687d", "32124": "29f80b058fd037c8c4a22ad0638ca7d833aa264e", "32127": "f3f3a804d7386e80003655c44d0a9faa707a618f", "32137": "20bb279d1f7602acdba4c13853b3c7d086aaf8db", "32140": "53acd0fe52cb5d8c6f5a86a1fc1352809240b68d", "32141": "189d2f304c73a40dd2d2d38f6203ff9d41cbd48e", "32145": "ad91259f20529306efe445f5a1da4dccc8c81b5a", "32155": "ee5d4ce151c633499b02abc85a0cbb863f3254f8", "32156": "2f8b8e7f1aa628289b92cfc5bdfc7907688962b1", "32157": "15599753b63f10748ffb374aacd37dbb37806a37", "32163": "bfe68b4641cd918f9f4d9f1a60f2f3e27fd707c8", "32173": "ae943bd7a02fe6ad93df619cce61cbad1a694c57", "32177": "ae6bf39b310ed5bb46349c831a05f55bba921dcc", "32181": "0bf24792d69ebc2024821adafd63ee37d0110cd3", "32182": "b4f17015ceba5dde8b720cb03992cbe6186604dc", "32188": "257757755b1c2bea22f3b78da392df07b809788f", "32200": "b22f7fa552c03aa7f6b9b4d661470d0173f8db5d", "32207": "681ab94222a9ba5f7b39f768f0ab92873905541a", "32212": "21829b5ddb8f50292dd302fff5c9aad1c4b1998a", "32213": "d2c713bce62974f7a17aab3e556d0bf14eebab3c", "32219": "df626e43ac3c99da2aeb005709d77395bd717e6a", "32223": "0c22fa1da475531aa31b5c67f427b5e1461835b5", "32224": "14684bbae31918a394d61c75c23edee42d6c9761", "32231": "8694eb00f8a3c0dede331fe60c0415bfaafef631", "32242": "4ee3fdd85c8d78da24c166a4127e8bc7bc8dd469", "32247": "b0b7c154ae5691310d56ea6c738a6b14c6692224", "32249": "5ceb8a6a031ddff26a7ede413db1b53edb64166a", "32254": "93c7306836aef3cb62e3cc25efeeae1a8dc8bbde", "32271": "0c8820b6e4f9c49f55e96fcbb297073a887eb37b", "32279": "8610e14f8a9acd488253444b8e551fb3e0d60ef7", "32282": "625650fa69c312f6d9b712eb41baf33dac1be3de", "32286": "1dc23d7a1a798151a45ce1d72954821d61728411", "32289": "3e6a39a73c2ca39e073e4b58117f59e92b3b2313", "32291": "7c2a58d51f4528827e9bfe9c43d06c5c1716bfb8", "32295": "0a4811677ee378c07a17062cedfbdcf3f9f40975", "32300": "ff9344f3d8d11d38fa3a2497199113e5bac9537c", "32304": "0e4e418eb2d34001724923b83111d5bb92edb4d1", "32321": "ffc0f66676b4835eb1bdd3f3ecab025e9c1be9fe", "32322": "86c7599d996368899898349185df068c4e2c5bd7", "32324": "53234c5b6bae7827fed9c74072cb059d33c476ba", "32333": "083ab6fcb6bfe2b4f454befcb1c585267b39e5fc", "32335": "af930a9aa4f55361a66051ac9ef151cda3742bf8", "32338": "80d21c37672dbb4b2439fbfb19b8d5e28d7f20ab", "32342": "b4ffba9e225971b9abe59aa28146197eb9910cb0", "32363": "239e16319116ab7445c0557bb08783ab2d60673d", "32371": "76511995f7804727c6f0494ca05e6e3f4d4f5430", "32372": "aee7f594f5d82ba75bcb8d720066ce18c727d0d1", "32374": "2e481f114169396660f0051eee1bcf6bcddfd556", "32376": "3e47fa91b6ed73f358105f2a1c6501e14f633bba", "32381": "64432e1cf65fc87c763737aa6422bb92d3573786", "32382": "e947074f63c6602ae15cd57b1fa4f6658040cff7", "32387": "7ec1bfc2ab7425bcd984d631b5bfeb9082ce11bf", "32391": "70442b9ee3753a6d63a9b2bfd35e3e51cadce230", "32394": "dbde1da1954be91b9a0a12c9a109c17cd109bc76", "32411": "c4d221ddcb9171f5bb05f7fe0dd0b96f7d532331", "32420": "86301acc28bb70f0e18f4be0e0b2d1e694e897ef", "32430": "85574f9cb847f39124816e6bf8a02fbf9550bd32", "32441": "9c9c8582dff9f4563aa130ef89f155bad0051493", "32442": "b728b2e8b192857f3522007328fa66909ed68787", "32444": "75db1bc2dbd716016170241d8daae97624d01252", "32453": "a7698a8bd853f1f32281ef635c7d4a827383d5fd", "32457": "3eb00d83ca40b458065d2739c0a7d60098e05701", "32465": "433600e68fbb12e72d8c5e0707916f5603bb7057", "32487": "c7d5f58d490e19680a4dc3d530f969baab033f2f", "32533": "dc580a8ef5ee2a8aea80498388690e2213118efd", "32604": "affaa62b1d053f3349e766aee91f397267a72656", "32607": "2cce02414d4a7161f0d105450c196d94b1182220", "32611": "96a0bc861ad2ba3c63db0326b42b41ddabeb2aff", "32617": "ce00ba817e7592c8e14f7610dd1f13ad694a3e5d", "32625": "e411c29625e66f7e440f1acce4069e01201cf122"}, "revision_to_date": {"382": 1264603663000, "395": 1265024295000, "587": 1269007740000, "590": 1269244318000, "646": 1270698297000, "745": 1272878771000, "755": 1272909852000, "811": 1273294444000, "813": 1273337313000, "826": 1273550555000, "998": 1277561666000, "1016": 1277824675000, "1131": 1279558872000, "1207": 1280235748000, "1288": 1281104090000, "1915": 1286358759000, "1917": 1286371631000, "1919": 1286373337000, "1969": 1286782666000, "1977": 1286812002000, "2701": 1292596297000, "2711": 1292968871000, "2743": 1294669325000, "3102": 1298808434000, "3151": 1299078131000, "3212": 1299680572000, "3289": 1300670714000, "3741": 1302729559000, "3905": 1304345121000, "4037": 1305108339000, "4054": 1305126138000, "4684": 1309505367000, "4696": 1309545528000, "6177": 1316527045000, "6225": 1316642399000, "6511": 1318977607000, "7872": 1326216418000, "7904": 1326287141000, "7919": 1326426441000, "9331": 1336328405000, "9349": 1336407543000, "9357": 1336426836000, "9369": 1336524866000, "9799": 1341415689000, "10413": 1346780365000, "10436": 1346788092000, "10457": 1346981442000, "10778": 1349734773000, "12368": 1358801181000, "12373": 1358806382000, "12748": 1361636276000, "14515": 1375060310000, "14698": 1375915741000, "14725": 1375972053000, "16940": 1401972588000, "17074": 1404172403000, "17075": 1404240383000, "17279": 1405354512000, "17645": 1406899808000, "17934": 1409835738000, "19198": 1425667359000, "19199": 1425681522000, "19375": 1427396256000, "19504": 1429027572000, "19920": 1436588422000, "20502": 1445007457000, "20509": 1445013082000, "20952": 1445953225000, "20955": 1445958667000, "21113": 1446753465000, "21126": 1446818031000, "21322": 1450749753000, "21323": 1450761225000, "21601": 1455802186000, "21602": 1455802246000, "22265": 1473791605000, "22268": 1473799038000, "22283": 1473882154000, "22393": 1475007587000, "22702": 1478902517000, "23197": 1497903977000, "23280": 1499947923000, "23283": 1499952302000, "23307": 1500281648000, "23480": 1502470027000, "23768": 1505921382000, "24417": 1531668719000, "24644": 1535551327000, "24809": 1537887812000, "25159": 1542875805000, "25261": 1545209521000, "25563": 1551431215000, "25750": 1556378170000, "25758": 1556603560000, "25766": 1556634531000, "25767": 1556635319000, "25841": 1557442357000, "25874": 1557893876000, "25910": 1558616196000, "26278": 1564406958000, "26284": 1558572641000, "26819": 1573637668000, "26820": 1573476950000, "26881": 1574093837000, "26890": 1574244189000, "26944": 1574933073000, "26953": 1575301264000, "27063": 1577976510000, "27300": 1582908441000, "27325": 1583315487000, "27498": 1588010313000, "27571": 1588689638000, "27604": 1589270282000, "27674": 1589872045000, "27937": 1593854670000, "28086": 1592994930000, "28255": 1599747257000, "28261": 1600274505000, "28269": 1600378277000, "28272": 1600458232000, "28277": 1600722669000, "28278": 1600789062000, "28284": 1600865667000, "28288": 1600968970000, "28291": 1601106935000, "28296": 1601326769000, "28302": 1601415150000, "28306": 1601462345000, "28308": 1601589341000, "28311": 1601660413000, "28314": 1601930618000, "28320": 1602017230000, "28326": 1602089300000, "28333": 1602190160000, "28339": 1602263563000, "28340": 1602436405000, "28345": 1602536302000, "28347": 1602591864000, "28357": 1602693776000, "28360": 1602796581000, "28361": 1602859901000, "28365": 1603135307000, "28367": 1603210848000, "28371": 1603296704000, "28373": 1603378269000, "28376": 1603484187000, "28377": 1603729650000, "28381": 1603813015000, "28390": 1603918365000, "28392": 1603993849000, "28396": 1604082959000, "28397": 1604157689000, "28404": 1604266317000, "28413": 1604338820000, "28416": 1604443088000, "28417": 1604518746000, "28418": 1604585464000, "28426": 1604687645000, "28428": 1604867994000, "28429": 1604916743000, "28435": 1605029333000, "28439": 1605135329000, "28443": 1605211856000, "28449": 1605292115000, "28450": 1605376572000, "28452": 1605564612000, "28454": 1605628238000, "28460": 1605722026000, "28462": 1605822301000, "28468": 1605911343000, "28469": 1606015242000, "28474": 1606161074000, "28476": 1606336705000, "28481": 1606416080000, "28485": 1606497935000, "28487": 1606765444000, "28495": 1606821855000, "28497": 1606904333000, "28499": 1606925797000, "28501": 1606931617000, "28502": 1607004204000, "28505": 1607116223000, "28506": 1607613543000, "28507": 1607723835000, "28510": 1607961058000, "28516": 1608059116000, "28520": 1608136519000, "28524": 1608242770000, "28527": 1608307759000, "28529": 1608395895000, "28532": 1608486943000, "28536": 1608587907000, "28541": 1608647213000, "28547": 1608676289000, "28550": 1609623728000, "28551": 1609698314000, "28554": 1609772780000, "28557": 1609840352000, "28561": 1609944537000, "28565": 1610128553000, "28566": 1610214433000, "28567": 1610304129000, "28572": 1610387413000, "28575": 1610461836000, "28580": 1610553773000, "28582": 1610641692000, "28584": 1610821727000, "28585": 1610915313000, "28588": 1610996785000, "28625": 1611052138000, "28629": 1611096802000, "28631": 1611164131000, "28633": 1611255467000, "28639": 1611341861000, "28644": 1611414840000, "28646": 1611487810000, "28653": 1611614513000, "28659": 1611689734000, "28663": 1611786407000, "28667": 1611868041000, "28670": 1611929245000, "28673": 1612010107000, "28674": 1612054336000, "28687": 1612217026000, "28688": 1612286029000, "28695": 1612393433000, "28696": 1612446975000, "28697": 1612514236000, "28702": 1612635631000, "28706": 1612696745000, "28712": 1612872626000, "28715": 1612885946000, "28720": 1612981796000, "28727": 1613076767000, "28734": 1613159543000, "28737": 1613400754000, "28740": 1613569280000, "28748": 1613674543000, "28751": 1613731449000, "28753": 1613840479000, "28761": 1614025369000, "28764": 1614104321000, "28767": 1614147824000, "28775": 1614262574000, "28779": 1614447340000, "28782": 1614618476000, "28786": 1614683996000, "28789": 1614793397000, "28790": 1615128856000, "28791": 1615226636000, "28792": 1615308357000, "28794": 1615382782000, "28797": 1615484044000, "28801": 1615590149000, "28802": 1615592700000, "28804": 1615733031000, "28808": 1615834814000, "28811": 1615930546000, "28817": 1615992780000, "28820": 1616089367000, "28827": 1616186648000, "28829": 1616249229000, "28834": 1616353572000, "28840": 1616519345000, "28841": 1616701156000, "28851": 1617400845000, "28853": 1617566024000, "28855": 1617640124000, "28859": 1617737608000, "28861": 1617832061000, "28867": 1617916880000, "28878": 1617992344000, "28879": 1618175593000, "28883": 1618257581000, "28890": 1618347639000, "28893": 1618413717000, "28895": 1618490002000, "28898": 1618600033000, "28905": 1618868919000, "28914": 1618954142000, "28917": 1619040868000, "28920": 1619110246000, "28922": 1619178650000, "28928": 1619467448000, "28936": 1619544136000, "29084": 1619600857000, "29085": 1619617061000, "29086": 1619725616000, "29088": 1619739533000, "29090": 1620050725000, "29092": 1620244799000, "29093": 1620265097000, "29097": 1620677421000, "29106": 1620770403000, "29108": 1620920636000, "29109": 1621006227000, "29110": 1621032016000, "29111": 1621172982000, "29113": 1621241554000, "29115": 1621364951000, "29119": 1621431262000, "29121": 1621520828000, "29123": 1621605580000, "29125": 1621709722000, "29126": 1621878405000, "29128": 1621944157000, "29131": 1622043901000, "29138": 1622124056000, "29142": 1622233878000, "29146": 1622489783000, "29156": 1622582567000, "29157": 1622648501000, "29164": 1622728054000, "29180": 1623250683000, "29185": 1623445015000, "29189": 1623510849000, "29190": 1623544407000, "29203": 1623793687000, "29215": 1623965080000, "29225": 1624040252000, "29227": 1624091050000, "29228": 1624219173000, "29229": 1624304793000, "29231": 1624373201000, "29233": 1624376492000, "29235": 1624391134000, "29240": 1624465784000, "29245": 1624562451000, "29246": 1624606131000, "29258": 1624736650000, "29262": 1624805941000, "29279": 1624903928000, "29286": 1624992439000, "29293": 1625090236000, "29294": 1625105021000, "29295": 1625431412000, "29296": 1625491027000, "29313": 1625595144000, "29318": 1625657660000, "29319": 1625751948000, "29322": 1625848516000, "29325": 1625952066000, "29327": 1626010586000, "29328": 1626111448000, "29340": 1626196541000, "29344": 1626363236000, "29349": 1626711194000, "29364": 1626810193000, "29371": 1626899379000, "29376": 1626986049000, "29381": 1627065892000, "29383": 1627161489000, "29387": 1627314805000, "29401": 1627418844000, "29404": 1627489158000, "29409": 1627574925000, "29414": 1627660909000, "29415": 1627719890000, "29420": 1627906614000, "29421": 1627974960000, "29425": 1628111422000, "29429": 1628181136000, "29435": 1628283892000, "29443": 1628368786000, "29446": 1628440292000, "29453": 1628538236000, "29454": 1628605886000, "29455": 1628675255000, "29457": 1628892021000, "29458": 1629060700000, "29469": 1629148355000, "29541": 1630592131000, "29548": 1630682386000, "29550": 1630790223000, "29551": 1630863632000, "29572": 1630935898000, "29586": 1631009128000, "29591": 1631035486000, "29598": 1631116383000, "29609": 1631193014000, "29611": 1631268037000, "29621": 1631548012000, "29636": 1631623921000, "29638": 1631647186000, "29644": 1631721222000, "29648": 1631796656000, "29652": 1631898294000, "29656": 1631979808000, "29657": 1632053184000, "29662": 1632171877000, "29665": 1632243233000, "29667": 1632346710000, "29733": 1632414516000, "29735": 1632423037000, "29742": 1632516259000, "29750": 1632746318000, "29753": 1632820895000, "29757": 1632916788000, "29761": 1632994638000, "29765": 1633110693000, "29766": 1633193599000, "29768": 1633355552000, "29776": 1633467847000, "29783": 1633621378000, "29788": 1633724151000, "29789": 1633749561000, "29790": 1633835632000, "29795": 1634072187000, "29798": 1634142184000, "29805": 1634230269000, "29806": 1634295072000, "29807": 1634399117000, "29808": 1634426648000, "29813": 1634558965000, "29815": 1634655567000, "29828": 1634761299000, "29839": 1634850335000, "29844": 1634909602000, "29858": 1635021251000, "29865": 1635104837000, "29997": 1635154787000, "29999": 1635179228000, "30002": 1635285319000, "30010": 1635365351000, "30013": 1635455200000, "30023": 1635527737000, "30028": 1635604153000, "30035": 1635850978000, "30046": 1635966997000, "30053": 1636041350000, "30066": 1636132510000, "30068": 1636189566000, "30070": 1636288882000, "30074": 1636385531000, "30076": 1636488027000, "30077": 1636582028000, "30078": 1636658652000, "30085": 1636756391000, "30086": 1636838462000, "30096": 1636999437000, "30104": 1637085139000, "30106": 1637168632000, "30112": 1637262498000, "30116": 1637319488000, "30118": 1637418893000, "30123": 1637618997000, "30128": 1637705763000, "30135": 1637777927000, "30145": 1637864181000, "30155": 1637956585000, "30156": 1638018624000, "30157": 1638057062000, "30165": 1638220668000, "30174": 1638310769000, "30179": 1638381381000, "30185": 1638476003000, "30189": 1638563225000, "30190": 1638654791000, "30198": 1638819086000, "30202": 1638888185000, "30203": 1638968646000, "30208": 1639082235000, "30212": 1639163319000, "30213": 1639179354000, "30215": 1639419807000, "30218": 1639518773000, "30225": 1639584547000, "30227": 1639692819000, "30233": 1639777744000, "30235": 1639934505000, "30238": 1640020199000, "30244": 1640116258000, "30248": 1640200222000, "30254": 1640294413000, "30259": 1640364531000, "30260": 1640431291000, "30500": 1640431648000, "30501": 1640701470000, "30502": 1640863001000, "30506": 1640982697000, "30507": 1641153417000, "30510": 1641224916000, "30515": 1641333323000, "30519": 1641416619000, "30520": 1641492764000, "30524": 1641589783000, "30525": 1641673299000, "30529": 1641854947000, "30533": 1641931361000, "30538": 1642009315000, "30542": 1642112955000, "30543": 1642155901000, "30544": 1642210241000, "30545": 1642433763000, "30550": 1642536525000, "30552": 1642593136000, "30556": 1642716792000, "30561": 1642787468000, "30564": 1642877522000, "30565": 1642958675000, "30577": 1643053590000, "30581": 1643130258000, "30586": 1643221209000, "30593": 1643294500000, "30615": 1643402974000, "30621": 1643494622000, "30622": 1643560106000, "30629": 1643638950000, "30635": 1643753378000, "30639": 1643824343000, "30640": 1643884968000, "30643": 1644011254000, "30646": 1644076710000, "30647": 1644187621000, "30650": 1644265942000, "30657": 1644357039000, "30665": 1644436807000, "30670": 1644533900000, "30675": 1644596303000, "30679": 1644699640000, "30694": 1644873503000, "30704": 1644958366000, "30708": 1645027501000, "30718": 1645117746000, "30723": 1645215955000, "30729": 1645306485000, "30730": 1645459454000, "30734": 1645557198000, "30739": 1645623865000, "30744": 1645739513000, "30748": 1645808094000, "30750": 1645892531000, "30754": 1645969117000, "30761": 1646084810000, "30762": 1646160183000, "30777": 1646262003000, "30782": 1646300512000, "30785": 1646416299000, "30787": 1646496694000, "30794": 1646682100000, "30804": 1646768999000, "30812": 1646859477000, "30818": 1646942986000, "30822": 1647030828000, "30839": 1647109345000, "30850": 1647209663000, "30862": 1647285454000, "30869": 1647371949000, "30873": 1647451140000, "30891": 1647557283000, "30906": 1647634447000, "30909": 1647727404000, "30910": 1647800199000, "30919": 1647896133000, "30933": 1647984962000, "30936": 1648054763000, "30944": 1648160658000, "30951": 1648243671000, "30955": 1648319349000, "30961": 1648406260000, "30965": 1648483673000, "30976": 1648581286000, "30983": 1648672004000, "30987": 1648748734000, "30996": 1648847676000, "30997": 1648901247000, "31003": 1649106907000, "31006": 1649150463000, "31018": 1649273792000, "31028": 1649350287000, "31040": 1649449476000, "31048": 1649539600000, "31049": 1649611192000, "31050": 1649689094000, "31129": 1651052569000, "31193": 1652277602000, "31309": 1652962489000, "31946": 1659704464000, "32111": 1662650106000, "32113": 1662708913000, "32124": 1662737945000, "32127": 1662814977000, "32137": 1663007356000, "32140": 1663074696000, "32141": 1663145605000, "32145": 1663256210000, "32155": 1663340845000, "32156": 1663401075000, "32157": 1663530485000, "32163": 1663598489000, "32173": 1663772127000, "32177": 1663870025000, "32181": 1663946749000, "32182": 1663986725000, "32188": 1664140855000, "32200": 1664229269000, "32207": 1664287910000, "32212": 1664388499000, "32213": 1664461587000, "32219": 1664562847000, "32223": 1664805604000, "32224": 1664868848000, "32231": 1665078930000, "32242": 1665164580000, "32247": 1665423832000, "32249": 1665524925000, "32254": 1665593694000, "32271": 1665696739000, "32279": 1665764076000, "32282": 1666028219000, "32286": 1666128017000, "32289": 1666180465000, "32291": 1666275645000, "32295": 1666549553000, "32300": 1666642605000, "32304": 1666714923000, "32321": 1666790709000, "32322": 1666777887000, "32324": 1666859255000, "32333": 1666971913000, "32335": 1667251255000, "32338": 1667319103000, "32342": 1667425048000, "32363": 1667500962000, "32371": 1667597404000, "32372": 1667655643000, "32374": 1667827735000, "32376": 1667920232000, "32381": 1668096180000, "32382": 1668161431000, "32387": 1668247510000, "32391": 1668370218000, "32394": 1668450346000, "32411": 1668542987000, "32420": 1668615570000, "32430": 1668712662000, "32441": 1668796144000, "32442": 1668967067000, "32444": 1669028816000, "32453": 1669155628000, "32457": 1669229533000, "32465": 1669314024000, "32487": 1669652459000, "32533": 1670501069000, "32604": 1672253566000, "32607": 1672335295000, "32611": 1672502364000, "32617": 1672681312000, "32625": 1672782103000}, "params": {"arch": ["x86_64"], "cpu": ["Intel Core Processor (Haswell, no TSX)"], "machine": ["sklearn-benchmark"], "num_cpu": ["8"], "os": ["Linux 4.15.0-20-generic"], "ram": ["16424684"], "python": ["3.8"], "numpy": [""], "scipy": [""], "cython": [""], "joblib": [""], "threadpoolctl": [""], "pandas": ["", null], "branch": ["main"]}, "graph_param_list": [{"arch": "x86_64", "cpu": "Intel Core Processor (Haswell, no TSX)", "machine": "sklearn-benchmark", "num_cpu": "8", "os": "Linux 4.15.0-20-generic", "ram": "16424684", "python": "3.8", "numpy": "", "scipy": "", "cython": "", "joblib": "", "threadpoolctl": "", "branch": "main", "pandas": null}, {"arch": "x86_64", "cpu": "Intel Core Processor (Haswell, no TSX)", "machine": "sklearn-benchmark", "num_cpu": "8", "os": "Linux 4.15.0-20-generic", "ram": "16424684", "python": "3.8", "numpy": "", "scipy": "", "cython": "", "joblib": "", "threadpoolctl": "", "pandas": "", "branch": "main"}], "benchmarks": {"cluster.KMeansBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_fit", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "a9d893de2d92e56e4dbeab4d7b7b4d5e00add3f4e993b164664b7ebbdd036dc7"}, "cluster.KMeansBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_predict", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "0f7d945338d774baae43a82dff7fe9f0db16ff6d1481b5afd437048b544396fc"}, "cluster.KMeansBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.peakmem_transform", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "576d76cb6e3aa82315e3d3dc6a2e8b7e58cb38bdd510df6801ab645465f4eb70"}, "cluster.KMeansBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_fit", "number": 0, "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "a8dbf56b4b6365cb1e3c23b71c7df95ae011632c95124496f8fd1c30430154ec", "warmup_time": 1}, "cluster.KMeansBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_predict", "number": 0, "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "611589f0c08131355c37720106ea132a2653a100660cd34884455259325b9c83", "warmup_time": 1}, "cluster.KMeansBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.KMeansBenchmark.time_transform", "number": 0, "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "8a02da09ca430e84b11161256032a2d4c08df103e4626718278e8b69b90acb0c", "warmup_time": 1}, "cluster.KMeansBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.track_test_score", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "track", "unit": "unit", "version": "67ff12752edbc7e4055ec0bddc293f22d59aec0eaa675c166f502a008bc22c59"}, "cluster.KMeansBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.KMeansBenchmark.track_train_score", "param_names": ["representation", "algorithm", "init"], "params": [["'dense'", "'sparse'"], ["'lloyd'", "'elkan'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:16", "timeout": 500, "type": "track", "unit": "unit", "version": "a5e07140ef3dd16920358a4c08c2f9f81d0e21f40bf5d8990b8a37b6a07c64e9"}, "cluster.MiniBatchKMeansBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.peakmem_fit", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:65", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "42f5ccf79079b60ff9fa8b0220a6b1fb951f46d27574d343f6e6b4b69dd8f1f0"}, "cluster.MiniBatchKMeansBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.peakmem_predict", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:65", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "03ee5b059682250c4b3d0793edf5a4978efb06c760148550f068e82dcb71e75f"}, "cluster.MiniBatchKMeansBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.peakmem_transform", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:65", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "f844a68fb0292b177c459487189f905d1afb89d79ab35a0539f9f4217b445ff2"}, "cluster.MiniBatchKMeansBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.MiniBatchKMeansBenchmark.time_fit", "number": 0, "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:65", "timeout": 500, "type": "time", "unit": "seconds", "version": "40617ec6fdd94e3a650dba98f8204c9779e63ae7803343b23e7368f7b068f26e", "warmup_time": 1}, "cluster.MiniBatchKMeansBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.MiniBatchKMeansBenchmark.time_predict", "number": 0, "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:65", "timeout": 500, "type": "time", "unit": "seconds", "version": "561b80fa4780c86ee698a0efd05c5d6c1bce24014006c5ec9096c2f3a960b9fe", "warmup_time": 1}, "cluster.MiniBatchKMeansBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "cluster.MiniBatchKMeansBenchmark.time_transform", "number": 0, "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "cluster:65", "timeout": 500, "type": "time", "unit": "seconds", "version": "2cf7a764c9fa1511ff1e1dee921060dc33eb0608e1cee96b782dc7b5d3f91f89", "warmup_time": 1}, "cluster.MiniBatchKMeansBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.track_test_score", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:65", "timeout": 500, "type": "track", "unit": "unit", "version": "7aeb8a20f66080e18e15f92e245fd1dd8de235e2f53d355596424dc7c30ae295"}, "cluster.MiniBatchKMeansBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchKMeansBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "cluster.MiniBatchKMeansBenchmark.track_train_score", "param_names": ["representation", "init"], "params": [["'dense'", "'sparse'"], ["'random'", "'k-means++'"]], "setup_cache_key": "cluster:65", "timeout": 500, "type": "track", "unit": "unit", "version": "b0c324767051682ea0bfc17c991f3de50e4876d683b1167c11ae8d4f2349b9c9"}, "decomposition.DictionaryLearningBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.peakmem_fit", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:41", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "8c3205268eade479bfda221734bf6129ab2a7b2bf4c59a8e6e855469f519672a"}, "decomposition.DictionaryLearningBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.peakmem_transform", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:41", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "b2c047a9e4d9d9cc6dd2d41a3738c21c183facbf5d609e8bfb354499f0b38ee4"}, "decomposition.DictionaryLearningBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.DictionaryLearningBenchmark.time_fit", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:41", "timeout": 500, "type": "time", "unit": "seconds", "version": "9f6c61216a35b8b5a205dbce3e4f541613c2e1df4cda9f85b16a7a41a02a9e02", "warmup_time": 1}, "decomposition.DictionaryLearningBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.DictionaryLearningBenchmark.time_transform", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:41", "timeout": 500, "type": "time", "unit": "seconds", "version": "a9786d7edfa47d44fb49632ba092edb63068a33298968990f071b58ad312e45a", "warmup_time": 1}, "decomposition.DictionaryLearningBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.track_test_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:41", "timeout": 500, "type": "track", "unit": "unit", "version": "022cecb50e5ba330d0728d08afbca34a130f0e74529bce6c8c93aca80a4bcae5"}, "decomposition.DictionaryLearningBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass DictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.DictionaryLearningBenchmark.track_train_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:41", "timeout": 500, "type": "track", "unit": "unit", "version": "6ed8ae7b04c1c5b4be0a5847795321be4c50195958c72642e1ca9367d838649d"}, "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_fit", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "cf54cbec149e048235b388e434462754421fc5f8593697b431e17bd01f79cbe1"}, "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.peakmem_transform", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "c9e62449ea399590080c790df85e63df815e88ceaa029196f9ea925d3acfecd7"}, "decomposition.MiniBatchDictionaryLearningBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.MiniBatchDictionaryLearningBenchmark.time_fit", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:75", "timeout": 500, "type": "time", "unit": "seconds", "version": "48d290a4fd2b0a9ecdd1a7add3b7e7b231d8df63e32889758ec0bbd8c1cb37ef", "warmup_time": 1}, "decomposition.MiniBatchDictionaryLearningBenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.MiniBatchDictionaryLearningBenchmark.time_transform", "number": 0, "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:75", "timeout": 500, "type": "time", "unit": "seconds", "version": "3ac7bfb8060c67e6dd13c37f1901d3f4274b8b0edfaf3d6a575d4e20ecbaf45e", "warmup_time": 1}, "decomposition.MiniBatchDictionaryLearningBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.track_test_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "track", "unit": "unit", "version": "a0774d6e8f922842e4b916076deab0ed00f152a84632f732cec174d5d619192f"}, "decomposition.MiniBatchDictionaryLearningBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass MiniBatchDictionaryLearningBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.MiniBatchDictionaryLearningBenchmark.track_train_score", "param_names": ["fit_algorithm", "n_jobs"], "params": [["'lars'", "'cd'"], ["1", "4"]], "setup_cache_key": "decomposition:75", "timeout": 500, "type": "track", "unit": "unit", "version": "13436574eaa40a2dd7b58fbef029cd2171941b963cec765dff95a1889f6a157a"}, "decomposition.PCABenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.peakmem_fit", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "1dc803fc882e472d9bc70274b900eb03304281cd2dff33ec3e3c039fffbb74a4"}, "decomposition.PCABenchmark.peakmem_transform": {"code": "class Transformer:\n    def peakmem_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.peakmem_transform", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "2b31c7c4510aca17a679729f995ba0b7d6548de119b989f414876912bc7851ff"}, "decomposition.PCABenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.PCABenchmark.time_fit", "number": 0, "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "4a753451bb0c872008db51c421599cf8badfcb691aab39aaa7822dad561241dc", "warmup_time": 1}, "decomposition.PCABenchmark.time_transform": {"code": "class Transformer:\n    def time_transform(self, *args):\n        self.estimator.transform(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "decomposition.PCABenchmark.time_transform", "number": 0, "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "decomposition:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "1f73bed6685d54963e63f4de9713d472d0ab242d57c6a0cfa54fac7d1e1e83ef", "warmup_time": 1}, "decomposition.PCABenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.track_test_score", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:16", "timeout": 500, "type": "track", "unit": "unit", "version": "2bf9b85b93e81f43bf6e2e900a8ef13fb83b9b9298c32d0808bda654eb57c0c3"}, "decomposition.PCABenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass PCABenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "decomposition.PCABenchmark.track_train_score", "param_names": ["svd_solver"], "params": [["'full'", "'arpack'", "'randomized'"]], "setup_cache_key": "decomposition:16", "timeout": 500, "type": "track", "unit": "unit", "version": "16881c7fae4abaa9923123fc258e6542b0b3aa0c232d2db206548668bced23bb"}, "ensemble.GradientBoostingClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:64", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "0bed7eba4859779600e1b1cb03539724eddad1419ad1332e897185f93bd3d6df"}, "ensemble.GradientBoostingClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:64", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "5f65eed561196ec366996fc83d2258f891bbe9608480b00948108fa794a3c81e"}, "ensemble.GradientBoostingClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.GradientBoostingClassifierBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:64", "timeout": 500, "type": "time", "unit": "seconds", "version": "5702f67868717f5884d82ed22b8940f7ff2b626a2b46e2a4b6e1173c83db484f", "warmup_time": 1}, "ensemble.GradientBoostingClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.GradientBoostingClassifierBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:64", "timeout": 500, "type": "time", "unit": "seconds", "version": "17e3a4098ef2254174162a060b1286418984a4be5438aefd71301bf6a8f4c13d", "warmup_time": 1}, "ensemble.GradientBoostingClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:64", "timeout": 500, "type": "track", "unit": "unit", "version": "55092be1f965aa51752829bda24b944bdb1222a6b8e5fdf0d4026c9580953dea"}, "ensemble.GradientBoostingClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.GradientBoostingClassifierBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "ensemble:64", "timeout": 500, "type": "track", "unit": "unit", "version": "cd78924c15421dcfc8b45a7d26a8b035a1e441c45612ee6ae169b9155e5a631b"}, "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_fit", "param_names": [], "params": [], "setup_cache_key": "ensemble:103", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "733ac3d039d12bcb9c7f00c745fad3c3723c29f21f67e444aabac276cbc3a916"}, "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.peakmem_predict", "param_names": [], "params": [], "setup_cache_key": "ensemble:103", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "ef8fbc52879ef0add38e7cec975a52bd207c7003e688e265dcc4839b0bcaa3a8"}, "ensemble.HistGradientBoostingClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.HistGradientBoostingClassifierBenchmark.time_fit", "number": 0, "param_names": [], "params": [], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:103", "timeout": 500, "type": "time", "unit": "seconds", "version": "6840b9adeccbde7fc736aae2aa37f9b118d3fa9a78f2e0b2f0a4f09503e1a48d", "warmup_time": 1}, "ensemble.HistGradientBoostingClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.HistGradientBoostingClassifierBenchmark.time_predict", "number": 0, "param_names": [], "params": [], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:103", "timeout": 500, "type": "time", "unit": "seconds", "version": "ce65e5d6c62eebe1e73935285f56bc6c7ecebde97fb73fb4b9370c9b5979288a", "warmup_time": 1}, "ensemble.HistGradientBoostingClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.track_test_score", "param_names": [], "params": [], "setup_cache_key": "ensemble:103", "timeout": 500, "type": "track", "unit": "unit", "version": "8c9a915f4dd669a61ceb38728602e43f84a976ebb06628f8026837eb7a5d30f6"}, "ensemble.HistGradientBoostingClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass HistGradientBoostingClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.HistGradientBoostingClassifierBenchmark.track_train_score", "param_names": [], "params": [], "setup_cache_key": "ensemble:103", "timeout": 500, "type": "track", "unit": "unit", "version": "43f6c225874e5193533ad56bdd398f471c7caa0f0f8c9a8ebb5486e10a2bec7f"}, "ensemble.RandomForestClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.peakmem_fit", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:24", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "14ca8ab81b54b4f2775c94fd794a13b049f48b9927979b964b90acc22ebf08a8"}, "ensemble.RandomForestClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.peakmem_predict", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:24", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "3febfd0d8977731921e7d366e6a585c8e405c0520f9a94415b96c6c334ed1c2f"}, "ensemble.RandomForestClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.RandomForestClassifierBenchmark.time_fit", "number": 0, "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:24", "timeout": 500, "type": "time", "unit": "seconds", "version": "7f77f2ea22b57af3ff27a86843c654c08e6aa926896f2c421666fd31d95ce65f", "warmup_time": 1}, "ensemble.RandomForestClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "ensemble.RandomForestClassifierBenchmark.time_predict", "number": 0, "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "ensemble:24", "timeout": 500, "type": "time", "unit": "seconds", "version": "6a93ee4dfb1d21e994eb8d7568e75ee99e0f416c9711bb2b45d1c022a27f0746", "warmup_time": 1}, "ensemble.RandomForestClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.track_test_score", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:24", "timeout": 500, "type": "track", "unit": "unit", "version": "a3b01d5f39647a3a6d6bfac31a005a5fdc82ad531a1b71f249ae2f4e98dc44c9"}, "ensemble.RandomForestClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RandomForestClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "ensemble.RandomForestClassifierBenchmark.track_train_score", "param_names": ["representation", "n_jobs"], "params": [["'dense'", "'sparse'"], ["1", "4"]], "setup_cache_key": "ensemble:24", "timeout": 500, "type": "track", "unit": "unit", "version": "42daa18fec647c7415a78ff56b84cf07b2253222c89f24baf5f12238463b9400"}, "linear_model.ElasticNetBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.peakmem_fit", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:183", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "aeb53df9e9543a762cf297b5697780eafb3cfbf2a7e750ad0f079ea50ff3d051"}, "linear_model.ElasticNetBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.peakmem_predict", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:183", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "27f5ef6022a3a4cdd5a0854b9428349a5e461bf638a76337760251639c9d7f02"}, "linear_model.ElasticNetBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.ElasticNetBenchmark.time_fit", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:183", "timeout": 500, "type": "time", "unit": "seconds", "version": "02947c3221cd53cf645dab6e61c787646637d66474795a722ec537ff85976c8c", "warmup_time": 1}, "linear_model.ElasticNetBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.ElasticNetBenchmark.time_predict", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:183", "timeout": 500, "type": "time", "unit": "seconds", "version": "4140a00f540d4dea5268a3813730d6fbb270e40b74285dbf046b3e26069f1287", "warmup_time": 1}, "linear_model.ElasticNetBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.track_test_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:183", "timeout": 500, "type": "track", "unit": "unit", "version": "1c0c2170cd23de65b973498cfc8dff584d9983a7513d2ead27d49594b092a280"}, "linear_model.ElasticNetBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass ElasticNetBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.ElasticNetBenchmark.track_train_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:183", "timeout": 500, "type": "track", "unit": "unit", "version": "6cff911c1163f327c86117f3dc306d62cdba87d9ea8068cc68977b61d151da78"}, "linear_model.LassoBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.peakmem_fit", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:224", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "8fa5824a898ff683065f60683a1805ae55dfdde209f22eb520e3dddac3b02688"}, "linear_model.LassoBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.peakmem_predict", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:224", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "2fd8dcd052ba7edddc85213c847b8fd149f36b0b9c0b058b88adae232e1fe0c6"}, "linear_model.LassoBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LassoBenchmark.time_fit", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:224", "timeout": 500, "type": "time", "unit": "seconds", "version": "d0f2ce5dce5564f0fc096b1e4ee47c583962a62baf6a13edf150b4edaf353e05", "warmup_time": 1}, "linear_model.LassoBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LassoBenchmark.time_predict", "number": 0, "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:224", "timeout": 500, "type": "time", "unit": "seconds", "version": "9adfa14dab87a3a8a4de49d179ab5891f08045e1b81194ae39643622cb6487c9", "warmup_time": 1}, "linear_model.LassoBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.track_test_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:224", "timeout": 500, "type": "track", "unit": "unit", "version": "b56564a7b1756eeff8bbe981fa28bfb58f992c09069c2672ae87e637ba91f565"}, "linear_model.LassoBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LassoBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LassoBenchmark.track_train_score", "param_names": ["representation", "precompute"], "params": [["'dense'", "'sparse'"], ["True", "False"]], "setup_cache_key": "linear_model:224", "timeout": 500, "type": "track", "unit": "unit", "version": "97c0e5ecdddd2ee7c31046ec01b6d29119975ffd6774712a778a26f8499350c4"}, "linear_model.LinearRegressionBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:119", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "a905fac8878f96b0ccc05296ca1cbb10654937aa04579453c79a4255ec7865f1"}, "linear_model.LinearRegressionBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:119", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "759535a8913b60467ef240fed4181399ff149efa33bea0eb69eed231df3f8876"}, "linear_model.LinearRegressionBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LinearRegressionBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:119", "timeout": 500, "type": "time", "unit": "seconds", "version": "e5dbbebbcad57689afbefadad2fb87cb71161a32a9d6caa162975a5b419f0f97", "warmup_time": 1}, "linear_model.LinearRegressionBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LinearRegressionBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:119", "timeout": 500, "type": "time", "unit": "seconds", "version": "ba279c28dffebbb04b7b173dee9e976b48b05ffbada322dd53d9a2de22ff70f6", "warmup_time": 1}, "linear_model.LinearRegressionBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:119", "timeout": 500, "type": "track", "unit": "unit", "version": "0641fe07389de5e5b9811f51f186e4a4a96a856eb50c8810c62734a593513594"}, "linear_model.LinearRegressionBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LinearRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LinearRegressionBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:119", "timeout": 500, "type": "track", "unit": "unit", "version": "5853e8435e7eba58f2264852c35444debdedaa05b29cccd9fef895ce848a5f06"}, "linear_model.LogisticRegressionBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.peakmem_fit", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:28", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "3b211361ab927e53d5697c6b9e81013a7575a9ce103d21adeb68544ea7a4e5dc"}, "linear_model.LogisticRegressionBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.peakmem_predict", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:28", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "be6101aa74d4f94ec846334788b859094ed4b1d36ca92bf7d693b3043a8d39da"}, "linear_model.LogisticRegressionBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LogisticRegressionBenchmark.time_fit", "number": 0, "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:28", "timeout": 500, "type": "time", "unit": "seconds", "version": "7cd42b119dd9bf6c8bf33ee70890f7ebaf0b159e0c0c8cd5b299c3f632725f21", "warmup_time": 1}, "linear_model.LogisticRegressionBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.LogisticRegressionBenchmark.time_predict", "number": 0, "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:28", "timeout": 500, "type": "time", "unit": "seconds", "version": "b9dd34b6a7b894f6afbd6e27f4d0cfe829c1b0e4af4f7203e56269b873ee049b", "warmup_time": 1}, "linear_model.LogisticRegressionBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.track_test_score", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:28", "timeout": 500, "type": "track", "unit": "unit", "version": "37e537f82f54da1d89003018c8370da6ac290d672b6343a457ee49dd444e3c9f"}, "linear_model.LogisticRegressionBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass LogisticRegressionBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.LogisticRegressionBenchmark.track_train_score", "param_names": ["representation", "solver", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'lbfgs'", "'saga'"], ["1", "4"]], "setup_cache_key": "linear_model:28", "timeout": 500, "type": "track", "unit": "unit", "version": "5647f2df8db098461a973d60cb900515f403287ed3e109a99151c94309e568f1"}, "linear_model.RidgeBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.peakmem_fit", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:78", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "d06a93be5cf39a0df663d696943713376c4ba4abb2568ebc0bc97fd2a2fd5173"}, "linear_model.RidgeBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.peakmem_predict", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:78", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "24e4dc55ce8e6b9311d26ca2936364cad3ddb0b8827b656a81886db508e69866"}, "linear_model.RidgeBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.RidgeBenchmark.time_fit", "number": 0, "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:78", "timeout": 500, "type": "time", "unit": "seconds", "version": "6ebbadd5cfeeb543e69ca73d777ab88bff49391965e0c0e3270868f1fa6bb385", "warmup_time": 1}, "linear_model.RidgeBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.RidgeBenchmark.time_predict", "number": 0, "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:78", "timeout": 500, "type": "time", "unit": "seconds", "version": "f41e9813a5f8239fbb0ef5e81982549e297ff18f751b7e4b42982972851b7cd0", "warmup_time": 1}, "linear_model.RidgeBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.track_test_score", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:78", "timeout": 500, "type": "track", "unit": "unit", "version": "663c821271fbdb18d0252832535191137787f37ad6d6397624c92edd96dc6f3f"}, "linear_model.RidgeBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass RidgeBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.RidgeBenchmark.track_train_score", "param_names": ["representation", "solver"], "params": [["'dense'", "'sparse'"], ["'auto'", "'svd'", "'cholesky'", "'lsqr'", "'sparse_cg'", "'sag'", "'saga'"]], "setup_cache_key": "linear_model:78", "timeout": 500, "type": "track", "unit": "unit", "version": "92bfe13d8da10b255d1c72982a3a88f70985b864b39584e51a184ea88116f35d"}, "linear_model.SGDRegressorBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.peakmem_fit", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:151", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "d81ea5fe5efd3e1ec085f0a2c66d712cfec7e2c4e03b19b7a50ab79dfd661f77"}, "linear_model.SGDRegressorBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.peakmem_predict", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:151", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "cf12939ffeb2f97f86ada7e454920a994d254a98a02eac5e34ea687f8ec11ad0"}, "linear_model.SGDRegressorBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.SGDRegressorBenchmark.time_fit", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:151", "timeout": 500, "type": "time", "unit": "seconds", "version": "cc477ee1fcfc2e853f5113072b49c7dc80acf8f2e19f83518368e1efe8dd5374", "warmup_time": 1}, "linear_model.SGDRegressorBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "linear_model.SGDRegressorBenchmark.time_predict", "number": 0, "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "linear_model:151", "timeout": 500, "type": "time", "unit": "seconds", "version": "fcd01e3604428cf2063cbbfe4e708974618533d55ec0784a787b8bb838a2ece9", "warmup_time": 1}, "linear_model.SGDRegressorBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.track_test_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:151", "timeout": 500, "type": "track", "unit": "unit", "version": "5c184c0b957ec177b911999a0cc2cd3996407b726efe5d7adeaeddea222a16d0"}, "linear_model.SGDRegressorBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SGDRegressorBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "linear_model.SGDRegressorBenchmark.track_train_score", "param_names": ["representation"], "params": [["'dense'", "'sparse'"]], "setup_cache_key": "linear_model:151", "timeout": 500, "type": "track", "unit": "unit", "version": "84040f29c546fcb4fb3fed1db35c198a88607a920f0d1aad43ae542738470257"}, "manifold.TSNEBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.peakmem_fit", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "5b07ad9c3bf4af00ff4022361ced135ee0591fe9a613dddb484f0142685497c4"}, "manifold.TSNEBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "manifold.TSNEBenchmark.time_fit", "number": 0, "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "manifold:15", "timeout": 500, "type": "time", "unit": "seconds", "version": "d7906ea0d1e8bee6103afdb924f0c5471c1c3e392feb7dbcc411b9e3f3535e6a", "warmup_time": 1}, "manifold.TSNEBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.track_test_score", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "track", "unit": "unit", "version": "7c865f9e53f16c8492cb36db3b656646d6585227ebfbf097102fda1e83f5e953"}, "manifold.TSNEBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass TSNEBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "manifold.TSNEBenchmark.track_train_score", "param_names": ["method"], "params": [["'exact'", "'barnes_hut'"]], "setup_cache_key": "manifold:15", "timeout": 500, "type": "track", "unit": "unit", "version": "92a5fc587f972e63dad98657097b1bcd64a743dfce5f07b3e1847ed8b720d46d"}, "metrics.PairwiseDistancesBenchmark.peakmem_pairwise_distances": {"code": "class PairwiseDistancesBenchmark:\n    def peakmem_pairwise_distances(self, *args):\n        pairwise_distances(self.X, **self.pdist_params)\n\n    def setup(self, *params):\n        representation, metric, n_jobs = params\n    \n        if representation == \"sparse\" and metric == \"correlation\":\n            raise NotImplementedError\n    \n        if Benchmark.data_size == \"large\":\n            if metric in (\"manhattan\", \"correlation\"):\n                n_samples = 8000\n            else:\n                n_samples = 24000\n        else:\n            if metric in (\"manhattan\", \"correlation\"):\n                n_samples = 4000\n            else:\n                n_samples = 12000\n    \n        data = _random_dataset(n_samples=n_samples, representation=representation)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.pdist_params = {\"metric\": metric, \"n_jobs\": n_jobs}", "name": "metrics.PairwiseDistancesBenchmark.peakmem_pairwise_distances", "param_names": ["representation", "metric", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'cosine'", "'euclidean'", "'manhattan'", "'correlation'"], ["1", "4"]], "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "f982061fc53163362f863b2455a1f2f660861c4a4357be712dcacab0682833db"}, "metrics.PairwiseDistancesBenchmark.time_pairwise_distances": {"code": "class PairwiseDistancesBenchmark:\n    def time_pairwise_distances(self, *args):\n        pairwise_distances(self.X, **self.pdist_params)\n\n    def setup(self, *params):\n        representation, metric, n_jobs = params\n    \n        if representation == \"sparse\" and metric == \"correlation\":\n            raise NotImplementedError\n    \n        if Benchmark.data_size == \"large\":\n            if metric in (\"manhattan\", \"correlation\"):\n                n_samples = 8000\n            else:\n                n_samples = 24000\n        else:\n            if metric in (\"manhattan\", \"correlation\"):\n                n_samples = 4000\n            else:\n                n_samples = 12000\n    \n        data = _random_dataset(n_samples=n_samples, representation=representation)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.pdist_params = {\"metric\": metric, \"n_jobs\": n_jobs}", "min_run_count": 2, "name": "metrics.PairwiseDistancesBenchmark.time_pairwise_distances", "number": 0, "param_names": ["representation", "metric", "n_jobs"], "params": [["'dense'", "'sparse'"], ["'cosine'", "'euclidean'", "'manhattan'", "'correlation'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "timeout": 500, "type": "time", "unit": "seconds", "version": "968c4646f4f823e76e062ccbbe50249793691ae13e472124d1ebd2642c86b5e0", "warmup_time": 1}, "model_selection.CrossValidationBenchmark.peakmem_crossval": {"code": "class CrossValidationBenchmark:\n    def peakmem_crossval(self, *args):\n        cross_val_score(self.clf, self.X, self.y, **self.cv_params)\n\n    def setup(self, *params):\n        (n_jobs,) = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=0)\n    \n        cv = 16 if Benchmark.data_size == \"large\" else 4\n    \n        self.cv_params = {\"n_jobs\": n_jobs, \"cv\": cv}", "name": "model_selection.CrossValidationBenchmark.peakmem_crossval", "param_names": ["n_jobs"], "params": [["1", "4"]], "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "4b6fc20c55d0bbbf2b9b56117a6725d0351eec991f183d04b136f1ce4552e0c7"}, "model_selection.CrossValidationBenchmark.time_crossval": {"code": "class CrossValidationBenchmark:\n    def time_crossval(self, *args):\n        cross_val_score(self.clf, self.X, self.y, **self.cv_params)\n\n    def setup(self, *params):\n        (n_jobs,) = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=0)\n    \n        cv = 16 if Benchmark.data_size == \"large\" else 4\n    \n        self.cv_params = {\"n_jobs\": n_jobs, \"cv\": cv}", "min_run_count": 2, "name": "model_selection.CrossValidationBenchmark.time_crossval", "number": 0, "param_names": ["n_jobs"], "params": [["1", "4"]], "rounds": 1, "sample_time": 0.01, "timeout": 20000, "type": "time", "unit": "seconds", "version": "9959454181a0ddb22a0ce5727c352955d47bf0ce97d2189ff73d567981c64587", "warmup_time": 1}, "model_selection.CrossValidationBenchmark.track_crossval": {"code": "class CrossValidationBenchmark:\n    def track_crossval(self, *args):\n        return float(cross_val_score(self.clf, self.X, self.y, **self.cv_params).mean())\n\n    def setup(self, *params):\n        (n_jobs,) = params\n    \n        data = _synth_classification_dataset(n_samples=50000, n_features=100)\n        self.X, self.X_val, self.y, self.y_val = data\n    \n        self.clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=0)\n    \n        cv = 16 if Benchmark.data_size == \"large\" else 4\n    \n        self.cv_params = {\"n_jobs\": n_jobs, \"cv\": cv}", "name": "model_selection.CrossValidationBenchmark.track_crossval", "param_names": ["n_jobs"], "params": [["1", "4"]], "timeout": 20000, "type": "track", "unit": "unit", "version": "5e7e6b0e0116bbc68953414ce4e0eec203cc51c80a71d897dd599172b82aeedd"}, "model_selection.GridSearchBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.peakmem_fit", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:51", "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "95b48fd99a9327cc7b96fbaf3fb68de0488e277098c5f71aa31f5bcc0af0aa35"}, "model_selection.GridSearchBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.peakmem_predict", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:51", "timeout": 20000, "type": "peakmemory", "unit": "bytes", "version": "c892cd859a96073eba53d60e549a73d8202c9d0e97f5469f5e0333d949ce8dce"}, "model_selection.GridSearchBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "model_selection.GridSearchBenchmark.time_fit", "number": 0, "param_names": ["n_jobs"], "params": [["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "model_selection:51", "timeout": 20000, "type": "time", "unit": "seconds", "version": "ce048ba169bd01fc98abe0f363fcaafc41dfc6d88ae4658795602e37fd0bd003", "warmup_time": 1}, "model_selection.GridSearchBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "model_selection.GridSearchBenchmark.time_predict", "number": 0, "param_names": ["n_jobs"], "params": [["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "model_selection:51", "timeout": 20000, "type": "time", "unit": "seconds", "version": "acfeae20f02fb4775c69f3a23452a495e43a2abb0e684954a33824913f37e3eb", "warmup_time": 1}, "model_selection.GridSearchBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.track_test_score", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:51", "timeout": 20000, "type": "track", "unit": "unit", "version": "ec63718f94ff0beda5889deafa3b1f1f3ff7750bf6254fce002cadda537bee4b"}, "model_selection.GridSearchBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass GridSearchBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "model_selection.GridSearchBenchmark.track_train_score", "param_names": ["n_jobs"], "params": [["1", "4"]], "setup_cache_key": "model_selection:51", "timeout": 20000, "type": "track", "unit": "unit", "version": "51575cdf87b95c5096592cecfc1f386cff2b52230b19a7bd6b1afee2fb55910c"}, "neighbors.KNeighborsClassifierBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.peakmem_fit", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "66acb7f2ea52ea49f9a5239c437782b0ac7cd030f150166dff686727e06ae1f5"}, "neighbors.KNeighborsClassifierBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.peakmem_predict", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:16", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "e7fb64f5f61911736101d3ca625806937a6bb4fc75b64a8ed0c9be1f37e0f10f"}, "neighbors.KNeighborsClassifierBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "neighbors.KNeighborsClassifierBenchmark.time_fit", "number": 0, "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "neighbors:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "455e6017e69db76a36673f135b8300f5288867804ae588240ef238340de7bc82", "warmup_time": 1}, "neighbors.KNeighborsClassifierBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "neighbors.KNeighborsClassifierBenchmark.time_predict", "number": 0, "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "neighbors:16", "timeout": 500, "type": "time", "unit": "seconds", "version": "6611e4000bd5b1d8935eb7407c10355bf476dfef925640b9a8445912b72c8183", "warmup_time": 1}, "neighbors.KNeighborsClassifierBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.track_test_score", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:16", "timeout": 500, "type": "track", "unit": "unit", "version": "95d25638754fb5c021b379d6f4f51868a7303bedb4868e52cac2a036eb0bc248"}, "neighbors.KNeighborsClassifierBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass KNeighborsClassifierBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "neighbors.KNeighborsClassifierBenchmark.track_train_score", "param_names": ["algorithm", "dimension", "n_jobs"], "params": [["'brute'", "'kd_tree'", "'ball_tree'"], ["'low'", "'high'"], ["1", "4"]], "setup_cache_key": "neighbors:16", "timeout": 500, "type": "track", "unit": "unit", "version": "1e1b6891a1563cf0c8ae446c751cfd6dec48cc2fcc4d0157f30a7189f05e938a"}, "svm.SVCBenchmark.peakmem_fit": {"code": "class Estimator:\n    def peakmem_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.peakmem_fit", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "b5099e172031e9a0f7b7706ec386c5bf36f9bd427f7d47274c66c6c39f5bf730"}, "svm.SVCBenchmark.peakmem_predict": {"code": "class Predictor:\n    def peakmem_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.peakmem_predict", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "peakmemory", "unit": "bytes", "version": "4a6611919a2e5a6cbd1f6c211b23857b3912da5e1484da897bf70155d62b7980"}, "svm.SVCBenchmark.time_fit": {"code": "class Estimator:\n    def time_fit(self, *args):\n        self.estimator.fit(self.X, self.y)\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "svm.SVCBenchmark.time_fit", "number": 0, "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "svm:14", "timeout": 500, "type": "time", "unit": "seconds", "version": "60f69bb46f97b00f249209ee47574d1508b9e81a8ba3ec0a8a3a430eb6aa719d", "warmup_time": 1}, "svm.SVCBenchmark.time_predict": {"code": "class Predictor:\n    def time_predict(self, *args):\n        self.estimator.predict(self.X)\n\nclass Estimator:\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "min_run_count": 2, "name": "svm.SVCBenchmark.time_predict", "number": 0, "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "rounds": 1, "sample_time": 0.01, "setup_cache_key": "svm:14", "timeout": 500, "type": "time", "unit": "seconds", "version": "ab64f47e62b03803ca9ee0734d6a0734af8278b39121b069d9abdf86a8e79285", "warmup_time": 1}, "svm.SVCBenchmark.track_test_score": {"code": "class Estimator:\n    def track_test_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_val_pred = self.estimator.predict(self.X_val)\n        else:\n            y_val_pred = None\n        return float(self.test_scorer(self.y_val, y_val_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.track_test_score", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "track", "unit": "unit", "version": "f04be6a642a0b71d7bb27a3b184c53cf61aa01dead2ec4bbc68bf22ea78b68b3"}, "svm.SVCBenchmark.track_train_score": {"code": "class Estimator:\n    def track_train_score(self, *args):\n        if hasattr(self.estimator, \"predict\"):\n            y_pred = self.estimator.predict(self.X)\n        else:\n            y_pred = None\n        return float(self.train_scorer(self.y, y_pred))\n\n    def setup(self, *params):\n        \"\"\"Generate dataset and load the fitted estimator\"\"\"\n        # This is run once per combination of parameters and per repeat so we\n        # need to avoid doing expensive operations there.\n    \n        if self.skip(params):\n            raise NotImplementedError\n    \n        self.X, self.X_val, self.y, self.y_val = self.make_data(params)\n    \n        est_path = get_estimator_path(\n            self, Benchmark.save_dir, params, Benchmark.save_estimators\n        )\n        with est_path.open(mode=\"rb\") as f:\n            self.estimator = pickle.load(f)\n    \n        self.make_scorers()\n\nclass SVCBenchmark:\n    def setup_cache(self):\n        super().setup_cache()", "name": "svm.SVCBenchmark.track_train_score", "param_names": ["kernel"], "params": [["'linear'", "'poly'", "'rbf'", "'sigmoid'"]], "setup_cache_key": "svm:14", "timeout": 500, "type": "track", "unit": "unit", "version": "30dfcaa0d1c48f402d28bf241f4c7c013ac533fbb528d470c427a34c237993f7"}}, "machines": {"sklearn-benchmark": {"arch": "x86_64", "cpu": "Intel Core Processor (Haswell, no TSX)", "machine": "sklearn-benchmark", "num_cpu": "8", "os": "Linux 4.15.0-20-generic", "ram": "16424684", "version": 1}}, "tags": {"0.1": 395, "0.1-beta": 382, "0.10": 7904, "0.10-branching": 7872, "0.11": 9357, "0.11-beta": 9331, "0.11-branching": 9349, "0.12": 10436, "0.12-branching": 10413, "0.12.1": 10778, "0.13": 12373, "0.13-branching": 12368, "0.13.1": 12748, "0.14": 14698, "0.14.1": 14725, "0.14a1": 14515, "0.15-branching": 17074, "0.15.0": 17279, "0.15.0b1": 16940, "0.15.0b2": 17075, "0.15.1": 17645, "0.15.2": 17934, "0.16-branching": 19198, "0.16.0": 19375, "0.16.1": 19504, "0.16b1": 19199, "0.17": 21113, "0.17-branching": 20502, "0.17.1": 21601, "0.17.1-1": 21602, "0.17b1": 20509, "0.18": 22393, "0.18.1": 22702, "0.18.2": 23197, "0.18rc": 22265, "0.18rc1": 22268, "0.18rc2": 22283, "0.19-branching": 23280, "0.19.0": 23480, "0.19.1": 23768, "0.19.2": 24417, "0.19b1": 23283, "0.19b2": 23307, "0.2": 590, "0.2-beta": 587, "0.20.0": 24809, "0.20.1": 25159, "0.20.2": 25261, "0.20.3": 25563, "0.20.4": 26284, "0.20rc1": 24644, "0.21.0": 25841, "0.21.1": 25874, "0.21.2": 25910, "0.21.3": 26278, "0.21b2": 25766, "0.21rc1": 25758, "0.21rc2": 25767, "0.22": 26953, "0.22.1": 27063, "0.22.2": 27300, "0.22.2.post1": 27325, "0.22rc1": 26820, "0.22rc2": 26881, "0.22rc2.post1": 26890, "0.22rc3": 26944, "0.23.0": 27604, "0.23.0rc1": 27571, "0.23.1": 27674, "0.23.2": 28086, "0.24.0": 28541, "0.24.0rc1": 28501, "0.24.1": 28625, "0.24.2": 29084, "0.3": 745, "0.4": 998, "0.5": 1969, "0.5.rc": 1915, "0.5.rc2": 1917, "0.5.rc3": 1919, "0.6-rc": 2701, "0.6.0": 2711, "0.7": 3151, "0.7-branching": 3102, "0.7.1": 3212, "0.8": 4037, "0.8-branching": 3905, "0.8.1": 4684, "0.9": 6225, "0.9-branching": 6177, "1.0": 29733, "1.0.1": 29997, "1.0.2": 30500, "1.0.rc1": 29586, "1.0.rc2": 29636, "1.1.0": 31193, "1.1.0rc1": 31129, "1.1.1": 31309, "1.1.2": 31946, "1.1.3": 32321, "1.2.0": 32533, "1.2.0rc1": 32487, "debian/0.10.0-1": 7919, "debian/0.11.0-1": 9369, "debian/0.11.0-2": 9799, "debian/0.12.0-1": 10457, "debian/0.16.1-2": 19920, "debian/0.17.0-1": 21126, "debian/0.17.0-3": 21322, "debian/0.17.0-4": 21323, "debian/0.17.0_b1+git14-g4e6829c-1": 20955, "debian/0.17.0_b1-1": 20952, "debian/0.2+svn625-1": 646, "debian/0.3-1": 755, "debian/0.3-2": 811, "debian/0.3-3": 813, "debian/0.3-4": 826, "debian/0.4-1": 1016, "debian/0.4-2": 1131, "debian/0.4-3": 1288, "debian/0.5-1": 1977, "debian/0.6.0.dfsg-1": 2743, "debian/0.7.1.dfsg-1": 3289, "debian/0.7.1.dfsg-3": 3741, "debian/0.8.0.dfsg-1": 4054, "debian/0.8.1.dfsg-1": 4696, "debian/0.9.0.dfsg-1": 6511, "sprint01": 1207}, "pages": [["", "Grid view", "Display as a agrid"], ["summarylist", "List view", "Display as a list"], ["regressions", "Show regressions", "Display information about recent regressions"]]}